{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channnel: F4-EOG (LEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path={\n",
    "    'data':\"F:/ISRUC-SLEEP_S3_DE.npz\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#from SLEEP_Utils import PrintScore,plot_confusion_matrix_ALL\n",
    "\n",
    "# 读取数据\n",
    "ReadList = np.load(Path['data'],allow_pickle=True)\n",
    "\n",
    "Fold_Num    = ReadList['Fold_Num']    #每折样本数 [31]\n",
    "#All_Data    = ReadList['All_Data']    #所有数据[samples, channels, features]\n",
    "#All_Label   = ReadList['All_Label']   #one-hot[samples, 5]\n",
    "#All_Label_n = ReadList['All_Label_n'] #数字[samples,]（0-W, 1-N1, 2-N2, 3-N3, 4-R）\n",
    "\n",
    "# Out-分31折数据——list-len=31\n",
    "Out_Data    = ReadList['Fold_Data']\n",
    "Out_Label   = ReadList['Fold_Label']\n",
    "#Out_Label_n = ReadList['Out_Label_n']\n",
    "\n",
    "print(\"Read data successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义——添加时间上下文\n",
    "def AddContext(x, context, label=False, dtype=float):\n",
    "    ret = []\n",
    "    assert context%2==1, \"context value error.\"\n",
    "    \n",
    "    cut = int(context/2)\n",
    "    if label:\n",
    "        for p in range(10):\n",
    "            tData=x[p][cut:x[p].shape[0]-cut]\n",
    "            ret.append(tData)\n",
    "            #print(tData.shape)\n",
    "    else:\n",
    "        for p in range(10):\n",
    "            tData=np.zeros([x[p].shape[0]- 2*cut,context,x[p].shape[1],x[p].shape[2]],dtype=dtype)\n",
    "            for i in range(cut,x[p].shape[0]-cut):\n",
    "                tData[i-cut]=x[p][i-cut:i+cut+1]\n",
    "            #print(tData.shape)\n",
    "            ret.append(tData)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context added successfully. 8549\n"
     ]
    }
   ],
   "source": [
    "context=5\n",
    "#添加时间上下文\n",
    "Out_Data    = AddContext(Out_Data,context)\n",
    "Out_Label   = AddContext(Out_Label,context,label=True)\n",
    "#Out_Label_n = AddContext(Out_Label_n,context,label=True)\n",
    "Fold_Num_c  = Fold_Num+1-context\n",
    "\n",
    "#for i in range(10):\n",
    "#    if i==0:    All_Label_n_context=Out_Label_n[i]\n",
    "#    else:       All_Label_n_context=np.concatenate((All_Label_n_context,Out_Label_n[i]))\n",
    "        \n",
    "print('Context added successfully.',np.sum(Fold_Num_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ok\n",
      "1 ok\n",
      "2 ok\n",
      "3 ok\n",
      "4 ok\n",
      "5 ok\n",
      "6 ok\n",
      "7 ok\n",
      "8 ok\n",
      "9 ok\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    Out_Data[i] = np.reshape(Out_Data[i],(-1,5,90))\n",
    "    print(i,'ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models,layers\n",
    "\n",
    "n_Context, n_Feature = 5,90\n",
    "def build():\n",
    "    ###############################################################################\n",
    "\n",
    "    data_layer = layers.Input(shape=(n_Context, n_Feature))\n",
    "    data_drop = layers.Dropout(0.2)(data_layer)\n",
    "\n",
    "    MLP_out = layers.Dense(300)(data_drop)\n",
    "    MLP_out = layers.LeakyReLU()(MLP_out)\n",
    "    MLP_out = layers.Dropout(0.5)(MLP_out)\n",
    "\n",
    "    MLP_out = layers.Dense(300)(MLP_out)\n",
    "    MLP_out = layers.LeakyReLU()(MLP_out)\n",
    "    MLP_out = layers.Dropout(0.5)(MLP_out)\n",
    "\n",
    "    LSTM_out = layers.LSTM(300)(MLP_out)\n",
    "\n",
    "    softmax = layers.Dense(5,activation='softmax')(LSTM_out)\n",
    "\n",
    "    model = models.Model(inputs = data_layer, outputs = softmax)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(lr=0.005, momentum=0.9),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['acc']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold # 0    Train: (7629, 5, 90)   Test: (920, 5, 90)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 5, 90)]           0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 5, 90)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5, 300)            27300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 5, 300)            0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 5, 300)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5, 300)            90300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 5, 300)            0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 5, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 1505      \n",
      "=================================================================\n",
      "Total params: 840,305\n",
      "Trainable params: 840,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7629 samples, validate on 920 samples\n",
      "Epoch 1/100\n",
      "7629/7629 - 4s - loss: 1.4746 - acc: 0.3788 - val_loss: 1.2520 - val_acc: 0.4228\n",
      "Epoch 2/100\n",
      "7629/7629 - 2s - loss: 1.1325 - acc: 0.5372 - val_loss: 1.0613 - val_acc: 0.5120\n",
      "Epoch 3/100\n",
      "7629/7629 - 2s - loss: 0.9680 - acc: 0.6140 - val_loss: 0.9316 - val_acc: 0.6152\n",
      "Epoch 4/100\n",
      "7629/7629 - 2s - loss: 0.8807 - acc: 0.6626 - val_loss: 0.8442 - val_acc: 0.6630\n",
      "Epoch 5/100\n",
      "7629/7629 - 2s - loss: 0.8252 - acc: 0.6862 - val_loss: 0.7987 - val_acc: 0.6870\n",
      "Epoch 6/100\n",
      "7629/7629 - 2s - loss: 0.7889 - acc: 0.6976 - val_loss: 0.7634 - val_acc: 0.7054\n",
      "Epoch 7/100\n",
      "7629/7629 - 2s - loss: 0.7594 - acc: 0.7032 - val_loss: 0.7282 - val_acc: 0.7207\n",
      "Epoch 8/100\n",
      "7629/7629 - 2s - loss: 0.7365 - acc: 0.7108 - val_loss: 0.7026 - val_acc: 0.7261\n",
      "Epoch 9/100\n",
      "7629/7629 - 2s - loss: 0.7063 - acc: 0.7205 - val_loss: 0.6830 - val_acc: 0.7315\n",
      "Epoch 10/100\n",
      "7629/7629 - 2s - loss: 0.6885 - acc: 0.7344 - val_loss: 0.6630 - val_acc: 0.7424\n",
      "Epoch 11/100\n",
      "7629/7629 - 2s - loss: 0.6702 - acc: 0.7348 - val_loss: 0.6453 - val_acc: 0.7467\n",
      "Epoch 12/100\n",
      "7629/7629 - 2s - loss: 0.6594 - acc: 0.7401 - val_loss: 0.6254 - val_acc: 0.7533\n",
      "Epoch 13/100\n",
      "7629/7629 - 2s - loss: 0.6423 - acc: 0.7451 - val_loss: 0.6206 - val_acc: 0.7543\n",
      "Epoch 14/100\n",
      "7629/7629 - 2s - loss: 0.6352 - acc: 0.7441 - val_loss: 0.6129 - val_acc: 0.7543\n",
      "Epoch 15/100\n",
      "7629/7629 - 2s - loss: 0.6289 - acc: 0.7512 - val_loss: 0.6031 - val_acc: 0.7576\n",
      "Epoch 16/100\n",
      "7629/7629 - 2s - loss: 0.6114 - acc: 0.7578 - val_loss: 0.5894 - val_acc: 0.7641\n",
      "Epoch 17/100\n",
      "7629/7629 - 2s - loss: 0.6090 - acc: 0.7597 - val_loss: 0.5862 - val_acc: 0.7630\n",
      "Epoch 18/100\n",
      "7629/7629 - 2s - loss: 0.6029 - acc: 0.7618 - val_loss: 0.5766 - val_acc: 0.7707\n",
      "Epoch 19/100\n",
      "7629/7629 - 2s - loss: 0.6022 - acc: 0.7627 - val_loss: 0.5724 - val_acc: 0.7728\n",
      "Epoch 20/100\n",
      "7629/7629 - 2s - loss: 0.5948 - acc: 0.7671 - val_loss: 0.5694 - val_acc: 0.7750\n",
      "Epoch 21/100\n",
      "7629/7629 - 2s - loss: 0.5810 - acc: 0.7689 - val_loss: 0.5656 - val_acc: 0.7772\n",
      "Epoch 22/100\n",
      "7629/7629 - 2s - loss: 0.5842 - acc: 0.7663 - val_loss: 0.5659 - val_acc: 0.7761\n",
      "Epoch 23/100\n",
      "7629/7629 - 2s - loss: 0.5761 - acc: 0.7683 - val_loss: 0.5541 - val_acc: 0.7815\n",
      "Epoch 24/100\n",
      "7629/7629 - 2s - loss: 0.5703 - acc: 0.7705 - val_loss: 0.5531 - val_acc: 0.7804\n",
      "Epoch 25/100\n",
      "7629/7629 - 2s - loss: 0.5696 - acc: 0.7748 - val_loss: 0.5478 - val_acc: 0.7880\n",
      "Epoch 26/100\n",
      "7629/7629 - 2s - loss: 0.5615 - acc: 0.7732 - val_loss: 0.5491 - val_acc: 0.7859\n",
      "Epoch 27/100\n",
      "7629/7629 - 2s - loss: 0.5707 - acc: 0.7676 - val_loss: 0.5459 - val_acc: 0.7902\n",
      "Epoch 28/100\n",
      "7629/7629 - 2s - loss: 0.5681 - acc: 0.7688 - val_loss: 0.5436 - val_acc: 0.7880\n",
      "Epoch 29/100\n",
      "7629/7629 - 2s - loss: 0.5580 - acc: 0.7761 - val_loss: 0.5455 - val_acc: 0.7848\n",
      "Epoch 30/100\n",
      "7629/7629 - 2s - loss: 0.5586 - acc: 0.7815 - val_loss: 0.5391 - val_acc: 0.7880\n",
      "Epoch 31/100\n",
      "7629/7629 - 2s - loss: 0.5570 - acc: 0.7780 - val_loss: 0.5399 - val_acc: 0.7902\n",
      "Epoch 32/100\n",
      "7629/7629 - 2s - loss: 0.5524 - acc: 0.7793 - val_loss: 0.5301 - val_acc: 0.7935\n",
      "Epoch 33/100\n",
      "7629/7629 - 2s - loss: 0.5500 - acc: 0.7829 - val_loss: 0.5381 - val_acc: 0.7880\n",
      "Epoch 34/100\n",
      "7629/7629 - 2s - loss: 0.5455 - acc: 0.7823 - val_loss: 0.5307 - val_acc: 0.7891\n",
      "Epoch 35/100\n",
      "7629/7629 - 2s - loss: 0.5506 - acc: 0.7814 - val_loss: 0.5271 - val_acc: 0.7913\n",
      "Epoch 36/100\n",
      "7629/7629 - 2s - loss: 0.5394 - acc: 0.7825 - val_loss: 0.5279 - val_acc: 0.7935\n",
      "Epoch 37/100\n",
      "7629/7629 - 2s - loss: 0.5377 - acc: 0.7829 - val_loss: 0.5256 - val_acc: 0.7935\n",
      "Epoch 38/100\n",
      "7629/7629 - 2s - loss: 0.5384 - acc: 0.7845 - val_loss: 0.5224 - val_acc: 0.7935\n",
      "Epoch 39/100\n",
      "7629/7629 - 2s - loss: 0.5361 - acc: 0.7839 - val_loss: 0.5197 - val_acc: 0.7957\n",
      "Epoch 40/100\n",
      "7629/7629 - 2s - loss: 0.5321 - acc: 0.7824 - val_loss: 0.5162 - val_acc: 0.7935\n",
      "Epoch 41/100\n",
      "7629/7629 - 2s - loss: 0.5344 - acc: 0.7840 - val_loss: 0.5152 - val_acc: 0.7935\n",
      "Epoch 42/100\n",
      "7629/7629 - 2s - loss: 0.5286 - acc: 0.7859 - val_loss: 0.5162 - val_acc: 0.7946\n",
      "Epoch 43/100\n",
      "7629/7629 - 2s - loss: 0.5264 - acc: 0.7909 - val_loss: 0.5152 - val_acc: 0.7967\n",
      "Epoch 44/100\n",
      "7629/7629 - 2s - loss: 0.5296 - acc: 0.7887 - val_loss: 0.5119 - val_acc: 0.7989\n",
      "Epoch 45/100\n",
      "7629/7629 - 2s - loss: 0.5270 - acc: 0.7859 - val_loss: 0.5126 - val_acc: 0.7967\n",
      "Epoch 46/100\n",
      "7629/7629 - 2s - loss: 0.5210 - acc: 0.7882 - val_loss: 0.5110 - val_acc: 0.7946\n",
      "Epoch 47/100\n",
      "7629/7629 - 2s - loss: 0.5210 - acc: 0.7900 - val_loss: 0.5108 - val_acc: 0.8011\n",
      "Epoch 48/100\n",
      "7629/7629 - 2s - loss: 0.5188 - acc: 0.7941 - val_loss: 0.5087 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "7629/7629 - 2s - loss: 0.5169 - acc: 0.7945 - val_loss: 0.5064 - val_acc: 0.8011\n",
      "Epoch 50/100\n",
      "7629/7629 - 2s - loss: 0.5225 - acc: 0.7892 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "7629/7629 - 2s - loss: 0.5234 - acc: 0.7888 - val_loss: 0.5037 - val_acc: 0.8022\n",
      "Epoch 52/100\n",
      "7629/7629 - 2s - loss: 0.5161 - acc: 0.7947 - val_loss: 0.5024 - val_acc: 0.8065\n",
      "Epoch 53/100\n",
      "7629/7629 - 2s - loss: 0.5165 - acc: 0.7907 - val_loss: 0.5040 - val_acc: 0.8022\n",
      "Epoch 54/100\n",
      "7629/7629 - 2s - loss: 0.5186 - acc: 0.7934 - val_loss: 0.5023 - val_acc: 0.8065\n",
      "Epoch 55/100\n",
      "7629/7629 - 2s - loss: 0.5095 - acc: 0.7960 - val_loss: 0.5032 - val_acc: 0.8011\n",
      "Epoch 56/100\n",
      "7629/7629 - 2s - loss: 0.5139 - acc: 0.7930 - val_loss: 0.5022 - val_acc: 0.8022\n",
      "Epoch 57/100\n",
      "7629/7629 - 2s - loss: 0.5174 - acc: 0.7886 - val_loss: 0.4953 - val_acc: 0.8054\n",
      "Epoch 58/100\n",
      "7629/7629 - 2s - loss: 0.5079 - acc: 0.7953 - val_loss: 0.4970 - val_acc: 0.8076\n",
      "Epoch 59/100\n",
      "7629/7629 - 2s - loss: 0.5102 - acc: 0.7962 - val_loss: 0.4962 - val_acc: 0.8043\n",
      "Epoch 60/100\n",
      "7629/7629 - 2s - loss: 0.5121 - acc: 0.7943 - val_loss: 0.4944 - val_acc: 0.8065\n",
      "Epoch 61/100\n",
      "7629/7629 - 2s - loss: 0.5108 - acc: 0.7943 - val_loss: 0.4961 - val_acc: 0.8054\n",
      "Epoch 62/100\n",
      "7629/7629 - 2s - loss: 0.5071 - acc: 0.7955 - val_loss: 0.4977 - val_acc: 0.8043\n",
      "Epoch 63/100\n",
      "7629/7629 - 2s - loss: 0.5028 - acc: 0.7976 - val_loss: 0.4963 - val_acc: 0.8054\n",
      "Epoch 64/100\n",
      "7629/7629 - 2s - loss: 0.4994 - acc: 0.8005 - val_loss: 0.4969 - val_acc: 0.8022\n",
      "Epoch 65/100\n",
      "7629/7629 - 2s - loss: 0.5051 - acc: 0.7984 - val_loss: 0.4927 - val_acc: 0.8065\n",
      "Epoch 66/100\n",
      "7629/7629 - 2s - loss: 0.5004 - acc: 0.7975 - val_loss: 0.4942 - val_acc: 0.8054\n",
      "Epoch 67/100\n",
      "7629/7629 - 2s - loss: 0.4981 - acc: 0.7989 - val_loss: 0.4950 - val_acc: 0.8065\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7629/7629 - 2s - loss: 0.4914 - acc: 0.8027 - val_loss: 0.4991 - val_acc: 0.8033\n",
      "Epoch 69/100\n",
      "7629/7629 - 2s - loss: 0.4977 - acc: 0.8019 - val_loss: 0.4916 - val_acc: 0.8098\n",
      "Epoch 70/100\n",
      "7629/7629 - 2s - loss: 0.5039 - acc: 0.8004 - val_loss: 0.4899 - val_acc: 0.8098\n",
      "Epoch 71/100\n",
      "7629/7629 - 2s - loss: 0.4987 - acc: 0.8008 - val_loss: 0.4877 - val_acc: 0.8109\n",
      "Epoch 72/100\n",
      "7629/7629 - 2s - loss: 0.4927 - acc: 0.7993 - val_loss: 0.4891 - val_acc: 0.8087\n",
      "Epoch 73/100\n",
      "7629/7629 - 2s - loss: 0.4956 - acc: 0.7998 - val_loss: 0.4914 - val_acc: 0.8087\n",
      "Epoch 74/100\n",
      "7629/7629 - 2s - loss: 0.4893 - acc: 0.8043 - val_loss: 0.4891 - val_acc: 0.8098\n",
      "Epoch 75/100\n",
      "7629/7629 - 2s - loss: 0.4939 - acc: 0.7994 - val_loss: 0.4844 - val_acc: 0.8130\n",
      "Epoch 76/100\n",
      "7629/7629 - 2s - loss: 0.4956 - acc: 0.8012 - val_loss: 0.4892 - val_acc: 0.8065\n",
      "Epoch 77/100\n",
      "7629/7629 - 2s - loss: 0.4897 - acc: 0.8001 - val_loss: 0.4889 - val_acc: 0.8054\n",
      "Epoch 78/100\n",
      "7629/7629 - 2s - loss: 0.4883 - acc: 0.8039 - val_loss: 0.4863 - val_acc: 0.8098\n",
      "Epoch 79/100\n",
      "7629/7629 - 2s - loss: 0.4909 - acc: 0.8025 - val_loss: 0.4914 - val_acc: 0.8043\n",
      "Epoch 80/100\n",
      "7629/7629 - 2s - loss: 0.4862 - acc: 0.8063 - val_loss: 0.4838 - val_acc: 0.8109\n",
      "Epoch 81/100\n",
      "7629/7629 - 2s - loss: 0.4857 - acc: 0.8044 - val_loss: 0.4806 - val_acc: 0.8087\n",
      "Epoch 82/100\n",
      "7629/7629 - 2s - loss: 0.4869 - acc: 0.8073 - val_loss: 0.4840 - val_acc: 0.8098\n",
      "Epoch 83/100\n",
      "7629/7629 - 2s - loss: 0.4795 - acc: 0.8067 - val_loss: 0.4843 - val_acc: 0.8109\n",
      "Epoch 84/100\n",
      "7629/7629 - 2s - loss: 0.4873 - acc: 0.8048 - val_loss: 0.4840 - val_acc: 0.8076\n",
      "Epoch 85/100\n",
      "7629/7629 - 2s - loss: 0.4881 - acc: 0.8030 - val_loss: 0.4809 - val_acc: 0.8109\n",
      "Epoch 86/100\n",
      "7629/7629 - 2s - loss: 0.4801 - acc: 0.8077 - val_loss: 0.4857 - val_acc: 0.8109\n",
      "Epoch 87/100\n",
      "7629/7629 - 2s - loss: 0.4776 - acc: 0.8089 - val_loss: 0.4829 - val_acc: 0.8087\n",
      "Epoch 88/100\n",
      "7629/7629 - 2s - loss: 0.4844 - acc: 0.8030 - val_loss: 0.4841 - val_acc: 0.8076\n",
      "Epoch 89/100\n",
      "7629/7629 - 2s - loss: 0.4758 - acc: 0.8084 - val_loss: 0.4836 - val_acc: 0.8120\n",
      "Epoch 90/100\n",
      "7629/7629 - 2s - loss: 0.4855 - acc: 0.8042 - val_loss: 0.4827 - val_acc: 0.8076\n",
      "Epoch 91/100\n",
      "7629/7629 - 2s - loss: 0.4799 - acc: 0.8043 - val_loss: 0.4828 - val_acc: 0.8087\n",
      "Epoch 92/100\n",
      "7629/7629 - 2s - loss: 0.4782 - acc: 0.8065 - val_loss: 0.4828 - val_acc: 0.8087\n",
      "Epoch 93/100\n",
      "7629/7629 - 2s - loss: 0.4722 - acc: 0.8098 - val_loss: 0.4813 - val_acc: 0.8109\n",
      "Epoch 94/100\n",
      "7629/7629 - 2s - loss: 0.4808 - acc: 0.8081 - val_loss: 0.4880 - val_acc: 0.8098\n",
      "Epoch 95/100\n",
      "7629/7629 - 2s - loss: 0.4696 - acc: 0.8072 - val_loss: 0.4800 - val_acc: 0.8098\n",
      "Epoch 96/100\n",
      "7629/7629 - 2s - loss: 0.4742 - acc: 0.8111 - val_loss: 0.4776 - val_acc: 0.8065\n",
      "Epoch 97/100\n",
      "7629/7629 - 2s - loss: 0.4791 - acc: 0.8080 - val_loss: 0.4815 - val_acc: 0.8076\n",
      "Epoch 98/100\n",
      "7629/7629 - 2s - loss: 0.4678 - acc: 0.8101 - val_loss: 0.4827 - val_acc: 0.8065\n",
      "Epoch 99/100\n",
      "7629/7629 - 2s - loss: 0.4743 - acc: 0.8080 - val_loss: 0.4769 - val_acc: 0.8087\n",
      "Epoch 100/100\n",
      "7629/7629 - 2s - loss: 0.4756 - acc: 0.8071 - val_loss: 0.4766 - val_acc: 0.8087\n",
      "Evaluate 0.8130435\n",
      "Fold # 1    Train: (7642, 5, 90)   Test: (907, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7642 samples, validate on 907 samples\n",
      "Epoch 1/100\n",
      "7642/7642 - 4s - loss: 1.5121 - acc: 0.3575 - val_loss: 1.3319 - val_acc: 0.3738\n",
      "Epoch 2/100\n",
      "7642/7642 - 2s - loss: 1.1690 - acc: 0.5601 - val_loss: 1.1122 - val_acc: 0.5006\n",
      "Epoch 3/100\n",
      "7642/7642 - 2s - loss: 0.9865 - acc: 0.6254 - val_loss: 0.9659 - val_acc: 0.5744\n",
      "Epoch 4/100\n",
      "7642/7642 - 2s - loss: 0.8864 - acc: 0.6755 - val_loss: 0.8858 - val_acc: 0.5998\n",
      "Epoch 5/100\n",
      "7642/7642 - 2s - loss: 0.8257 - acc: 0.6914 - val_loss: 0.8449 - val_acc: 0.6108\n",
      "Epoch 6/100\n",
      "7642/7642 - 2s - loss: 0.7777 - acc: 0.7073 - val_loss: 0.8173 - val_acc: 0.6273\n",
      "Epoch 7/100\n",
      "7642/7642 - 2s - loss: 0.7449 - acc: 0.7143 - val_loss: 0.7981 - val_acc: 0.6318\n",
      "Epoch 8/100\n",
      "7642/7642 - 2s - loss: 0.7137 - acc: 0.7298 - val_loss: 0.7772 - val_acc: 0.6593\n",
      "Epoch 9/100\n",
      "7642/7642 - 2s - loss: 0.6912 - acc: 0.7321 - val_loss: 0.7749 - val_acc: 0.6604\n",
      "Epoch 10/100\n",
      "7642/7642 - 2s - loss: 0.6638 - acc: 0.7452 - val_loss: 0.7682 - val_acc: 0.6648\n",
      "Epoch 11/100\n",
      "7642/7642 - 2s - loss: 0.6510 - acc: 0.7471 - val_loss: 0.7539 - val_acc: 0.6725\n",
      "Epoch 12/100\n",
      "7642/7642 - 2s - loss: 0.6361 - acc: 0.7558 - val_loss: 0.7628 - val_acc: 0.6659\n",
      "Epoch 13/100\n",
      "7642/7642 - 2s - loss: 0.6257 - acc: 0.7554 - val_loss: 0.7658 - val_acc: 0.6648\n",
      "Epoch 14/100\n",
      "7642/7642 - 2s - loss: 0.6181 - acc: 0.7583 - val_loss: 0.7608 - val_acc: 0.6681\n",
      "Epoch 15/100\n",
      "7642/7642 - 2s - loss: 0.6021 - acc: 0.7669 - val_loss: 0.7542 - val_acc: 0.6759\n",
      "Epoch 16/100\n",
      "7642/7642 - 2s - loss: 0.5991 - acc: 0.7647 - val_loss: 0.7589 - val_acc: 0.6714\n",
      "Epoch 17/100\n",
      "7642/7642 - 2s - loss: 0.5962 - acc: 0.7600 - val_loss: 0.7560 - val_acc: 0.6703\n",
      "Epoch 18/100\n",
      "7642/7642 - 2s - loss: 0.5839 - acc: 0.7701 - val_loss: 0.7590 - val_acc: 0.6725\n",
      "Epoch 19/100\n",
      "7642/7642 - 2s - loss: 0.5818 - acc: 0.7702 - val_loss: 0.7575 - val_acc: 0.6736\n",
      "Epoch 20/100\n",
      "7642/7642 - 2s - loss: 0.5771 - acc: 0.7706 - val_loss: 0.7523 - val_acc: 0.6792\n",
      "Epoch 21/100\n",
      "7642/7642 - 2s - loss: 0.5734 - acc: 0.7719 - val_loss: 0.7594 - val_acc: 0.6803\n",
      "Epoch 22/100\n",
      "7642/7642 - 2s - loss: 0.5719 - acc: 0.7774 - val_loss: 0.7606 - val_acc: 0.6759\n",
      "Epoch 23/100\n",
      "7642/7642 - 2s - loss: 0.5666 - acc: 0.7740 - val_loss: 0.7597 - val_acc: 0.6781\n",
      "Epoch 24/100\n",
      "7642/7642 - 2s - loss: 0.5634 - acc: 0.7799 - val_loss: 0.7507 - val_acc: 0.6847\n",
      "Epoch 25/100\n",
      "7642/7642 - 2s - loss: 0.5546 - acc: 0.7834 - val_loss: 0.7547 - val_acc: 0.6847\n",
      "Epoch 26/100\n",
      "7642/7642 - 2s - loss: 0.5508 - acc: 0.7817 - val_loss: 0.7647 - val_acc: 0.6748\n",
      "Epoch 27/100\n",
      "7642/7642 - 2s - loss: 0.5480 - acc: 0.7861 - val_loss: 0.7604 - val_acc: 0.6781\n",
      "Epoch 28/100\n",
      "7642/7642 - 2s - loss: 0.5473 - acc: 0.7809 - val_loss: 0.7538 - val_acc: 0.6880\n",
      "Epoch 29/100\n",
      "7642/7642 - 2s - loss: 0.5400 - acc: 0.7854 - val_loss: 0.7590 - val_acc: 0.6836\n",
      "Epoch 30/100\n",
      "7642/7642 - 2s - loss: 0.5376 - acc: 0.7868 - val_loss: 0.7617 - val_acc: 0.6869\n",
      "Epoch 31/100\n",
      "7642/7642 - 2s - loss: 0.5450 - acc: 0.7845 - val_loss: 0.7608 - val_acc: 0.6880\n",
      "Epoch 32/100\n",
      "7642/7642 - 2s - loss: 0.5381 - acc: 0.7859 - val_loss: 0.7684 - val_acc: 0.6781\n",
      "Epoch 33/100\n",
      "7642/7642 - 2s - loss: 0.5335 - acc: 0.7859 - val_loss: 0.7554 - val_acc: 0.6946\n",
      "Epoch 34/100\n",
      "7642/7642 - 2s - loss: 0.5374 - acc: 0.7875 - val_loss: 0.7591 - val_acc: 0.6836\n",
      "Epoch 35/100\n",
      "7642/7642 - 2s - loss: 0.5303 - acc: 0.7872 - val_loss: 0.7576 - val_acc: 0.6880\n",
      "Epoch 36/100\n",
      "7642/7642 - 2s - loss: 0.5231 - acc: 0.7901 - val_loss: 0.7444 - val_acc: 0.7023\n",
      "Epoch 37/100\n",
      "7642/7642 - 2s - loss: 0.5228 - acc: 0.7905 - val_loss: 0.7535 - val_acc: 0.6957\n",
      "Epoch 38/100\n",
      "7642/7642 - 2s - loss: 0.5226 - acc: 0.7934 - val_loss: 0.7531 - val_acc: 0.7001\n",
      "Epoch 39/100\n",
      "7642/7642 - 2s - loss: 0.5210 - acc: 0.7961 - val_loss: 0.7625 - val_acc: 0.6924\n",
      "Epoch 40/100\n",
      "7642/7642 - 2s - loss: 0.5202 - acc: 0.7900 - val_loss: 0.7647 - val_acc: 0.6880\n",
      "Epoch 41/100\n",
      "7642/7642 - 2s - loss: 0.5200 - acc: 0.7913 - val_loss: 0.7738 - val_acc: 0.6847\n",
      "Epoch 42/100\n",
      "7642/7642 - 2s - loss: 0.5121 - acc: 0.7936 - val_loss: 0.7624 - val_acc: 0.6957\n",
      "Epoch 43/100\n",
      "7642/7642 - 2s - loss: 0.5112 - acc: 0.7984 - val_loss: 0.7618 - val_acc: 0.6924\n",
      "Epoch 44/100\n",
      "7642/7642 - 2s - loss: 0.5119 - acc: 0.7943 - val_loss: 0.7598 - val_acc: 0.6924\n",
      "Epoch 45/100\n",
      "7642/7642 - 2s - loss: 0.5125 - acc: 0.7952 - val_loss: 0.7633 - val_acc: 0.6935\n",
      "Epoch 46/100\n",
      "7642/7642 - 2s - loss: 0.5123 - acc: 0.7929 - val_loss: 0.7600 - val_acc: 0.7001\n",
      "Epoch 47/100\n",
      "7642/7642 - 2s - loss: 0.5097 - acc: 0.7939 - val_loss: 0.7624 - val_acc: 0.6957\n",
      "Epoch 48/100\n",
      "7642/7642 - 2s - loss: 0.5016 - acc: 0.8001 - val_loss: 0.7624 - val_acc: 0.7012\n",
      "Epoch 49/100\n",
      "7642/7642 - 2s - loss: 0.5079 - acc: 0.7955 - val_loss: 0.7598 - val_acc: 0.7023\n",
      "Epoch 50/100\n",
      "7642/7642 - 2s - loss: 0.4989 - acc: 0.8016 - val_loss: 0.7554 - val_acc: 0.7034\n",
      "Epoch 51/100\n",
      "7642/7642 - 2s - loss: 0.5036 - acc: 0.8029 - val_loss: 0.7539 - val_acc: 0.7067\n",
      "Epoch 52/100\n",
      "7642/7642 - 2s - loss: 0.4950 - acc: 0.8033 - val_loss: 0.7615 - val_acc: 0.6990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "7642/7642 - 2s - loss: 0.5019 - acc: 0.7981 - val_loss: 0.7535 - val_acc: 0.7067\n",
      "Epoch 54/100\n",
      "7642/7642 - 2s - loss: 0.4989 - acc: 0.8012 - val_loss: 0.7637 - val_acc: 0.7023\n",
      "Epoch 55/100\n",
      "7642/7642 - 2s - loss: 0.4972 - acc: 0.8021 - val_loss: 0.7592 - val_acc: 0.7023\n",
      "Epoch 56/100\n",
      "7642/7642 - 2s - loss: 0.4991 - acc: 0.7991 - val_loss: 0.7604 - val_acc: 0.6957\n",
      "Epoch 57/100\n",
      "7642/7642 - 2s - loss: 0.4943 - acc: 0.8083 - val_loss: 0.7650 - val_acc: 0.7001\n",
      "Epoch 58/100\n",
      "7642/7642 - 2s - loss: 0.4943 - acc: 0.8035 - val_loss: 0.7709 - val_acc: 0.6924\n",
      "Epoch 59/100\n",
      "7642/7642 - 2s - loss: 0.4945 - acc: 0.7994 - val_loss: 0.7633 - val_acc: 0.6990\n",
      "Epoch 60/100\n",
      "7642/7642 - 2s - loss: 0.4881 - acc: 0.8042 - val_loss: 0.7617 - val_acc: 0.7001\n",
      "Epoch 61/100\n",
      "7642/7642 - 2s - loss: 0.4882 - acc: 0.8069 - val_loss: 0.7719 - val_acc: 0.6968\n",
      "Epoch 62/100\n",
      "7642/7642 - 2s - loss: 0.4878 - acc: 0.8040 - val_loss: 0.7513 - val_acc: 0.7067\n",
      "Epoch 63/100\n",
      "7642/7642 - 2s - loss: 0.4877 - acc: 0.8067 - val_loss: 0.7597 - val_acc: 0.6979\n",
      "Epoch 64/100\n",
      "7642/7642 - 2s - loss: 0.4877 - acc: 0.8018 - val_loss: 0.7548 - val_acc: 0.7012\n",
      "Epoch 65/100\n",
      "7642/7642 - 2s - loss: 0.4881 - acc: 0.8048 - val_loss: 0.7634 - val_acc: 0.6979\n",
      "Epoch 66/100\n",
      "7642/7642 - 2s - loss: 0.4829 - acc: 0.8125 - val_loss: 0.7651 - val_acc: 0.6968\n",
      "Epoch 67/100\n",
      "7642/7642 - 2s - loss: 0.4854 - acc: 0.8031 - val_loss: 0.7527 - val_acc: 0.7045\n",
      "Epoch 68/100\n",
      "7642/7642 - 2s - loss: 0.4835 - acc: 0.8053 - val_loss: 0.7564 - val_acc: 0.7067\n",
      "Epoch 69/100\n",
      "7642/7642 - 2s - loss: 0.4816 - acc: 0.8078 - val_loss: 0.7630 - val_acc: 0.7023\n",
      "Epoch 70/100\n",
      "7642/7642 - 2s - loss: 0.4860 - acc: 0.8036 - val_loss: 0.7555 - val_acc: 0.7001\n",
      "Epoch 71/100\n",
      "7642/7642 - 2s - loss: 0.4768 - acc: 0.8099 - val_loss: 0.7509 - val_acc: 0.7012\n",
      "Epoch 72/100\n",
      "7642/7642 - 2s - loss: 0.4833 - acc: 0.8065 - val_loss: 0.7615 - val_acc: 0.6979\n",
      "Epoch 73/100\n",
      "7642/7642 - 2s - loss: 0.4803 - acc: 0.8052 - val_loss: 0.7639 - val_acc: 0.6979\n",
      "Epoch 74/100\n",
      "7642/7642 - 2s - loss: 0.4819 - acc: 0.8080 - val_loss: 0.7649 - val_acc: 0.6990\n",
      "Epoch 75/100\n",
      "7642/7642 - 2s - loss: 0.4799 - acc: 0.8069 - val_loss: 0.7408 - val_acc: 0.7089\n",
      "Epoch 76/100\n",
      "7642/7642 - 2s - loss: 0.4720 - acc: 0.8130 - val_loss: 0.7631 - val_acc: 0.6946\n",
      "Epoch 77/100\n",
      "7642/7642 - 2s - loss: 0.4741 - acc: 0.8110 - val_loss: 0.7534 - val_acc: 0.7067\n",
      "Epoch 78/100\n",
      "7642/7642 - 2s - loss: 0.4722 - acc: 0.8095 - val_loss: 0.7629 - val_acc: 0.7012\n",
      "Epoch 79/100\n",
      "7642/7642 - 2s - loss: 0.4770 - acc: 0.8109 - val_loss: 0.7584 - val_acc: 0.7012\n",
      "Epoch 80/100\n",
      "7642/7642 - 2s - loss: 0.4783 - acc: 0.8087 - val_loss: 0.7532 - val_acc: 0.7056\n",
      "Epoch 81/100\n",
      "7642/7642 - 2s - loss: 0.4687 - acc: 0.8168 - val_loss: 0.7485 - val_acc: 0.7023\n",
      "Epoch 82/100\n",
      "7642/7642 - 2s - loss: 0.4692 - acc: 0.8107 - val_loss: 0.7449 - val_acc: 0.7034\n",
      "Epoch 83/100\n",
      "7642/7642 - 2s - loss: 0.4747 - acc: 0.8118 - val_loss: 0.7581 - val_acc: 0.7078\n",
      "Epoch 84/100\n",
      "7642/7642 - 2s - loss: 0.4719 - acc: 0.8107 - val_loss: 0.7463 - val_acc: 0.7056\n",
      "Epoch 85/100\n",
      "7642/7642 - 2s - loss: 0.4672 - acc: 0.8120 - val_loss: 0.7468 - val_acc: 0.7012\n",
      "Epoch 86/100\n",
      "7642/7642 - 2s - loss: 0.4652 - acc: 0.8161 - val_loss: 0.7559 - val_acc: 0.7001\n",
      "Epoch 87/100\n",
      "7642/7642 - 2s - loss: 0.4687 - acc: 0.8139 - val_loss: 0.7515 - val_acc: 0.7078\n",
      "Epoch 88/100\n",
      "7642/7642 - 2s - loss: 0.4665 - acc: 0.8105 - val_loss: 0.7573 - val_acc: 0.7001\n",
      "Epoch 89/100\n",
      "7642/7642 - 2s - loss: 0.4691 - acc: 0.8118 - val_loss: 0.7585 - val_acc: 0.6968\n",
      "Epoch 90/100\n",
      "7642/7642 - 2s - loss: 0.4636 - acc: 0.8133 - val_loss: 0.7460 - val_acc: 0.7067\n",
      "Epoch 91/100\n",
      "7642/7642 - 2s - loss: 0.4633 - acc: 0.8203 - val_loss: 0.7552 - val_acc: 0.7034\n",
      "Epoch 92/100\n",
      "7642/7642 - 2s - loss: 0.4679 - acc: 0.8112 - val_loss: 0.7617 - val_acc: 0.6946\n",
      "Epoch 93/100\n",
      "7642/7642 - 2s - loss: 0.4663 - acc: 0.8131 - val_loss: 0.7485 - val_acc: 0.7078\n",
      "Epoch 94/100\n",
      "7642/7642 - 2s - loss: 0.4612 - acc: 0.8126 - val_loss: 0.7520 - val_acc: 0.7012\n",
      "Epoch 95/100\n",
      "7642/7642 - 2s - loss: 0.4604 - acc: 0.8147 - val_loss: 0.7629 - val_acc: 0.7001\n",
      "Epoch 96/100\n",
      "7642/7642 - 2s - loss: 0.4573 - acc: 0.8173 - val_loss: 0.7546 - val_acc: 0.7023\n",
      "Epoch 97/100\n",
      "7642/7642 - 2s - loss: 0.4629 - acc: 0.8144 - val_loss: 0.7583 - val_acc: 0.7012\n",
      "Epoch 98/100\n",
      "7642/7642 - 2s - loss: 0.4598 - acc: 0.8172 - val_loss: 0.7654 - val_acc: 0.7023\n",
      "Epoch 99/100\n",
      "7642/7642 - 2s - loss: 0.4577 - acc: 0.8137 - val_loss: 0.7623 - val_acc: 0.7012\n",
      "Epoch 100/100\n",
      "7642/7642 - 2s - loss: 0.4512 - acc: 0.8203 - val_loss: 0.7539 - val_acc: 0.7012\n",
      "Evaluate 0.70893055\n",
      "Fold # 2    Train: (7759, 5, 90)   Test: (790, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7759 samples, validate on 790 samples\n",
      "Epoch 1/100\n",
      "7759/7759 - 4s - loss: 1.4967 - acc: 0.3477 - val_loss: 1.2336 - val_acc: 0.5557\n",
      "Epoch 2/100\n",
      "7759/7759 - 2s - loss: 1.1328 - acc: 0.5704 - val_loss: 0.9730 - val_acc: 0.6595\n",
      "Epoch 3/100\n",
      "7759/7759 - 2s - loss: 0.9575 - acc: 0.6413 - val_loss: 0.8612 - val_acc: 0.7063\n",
      "Epoch 4/100\n",
      "7759/7759 - 2s - loss: 0.8700 - acc: 0.6797 - val_loss: 0.7898 - val_acc: 0.7114\n",
      "Epoch 5/100\n",
      "7759/7759 - 2s - loss: 0.8131 - acc: 0.6907 - val_loss: 0.7418 - val_acc: 0.7177\n",
      "Epoch 6/100\n",
      "7759/7759 - 2s - loss: 0.7730 - acc: 0.7070 - val_loss: 0.7143 - val_acc: 0.7241\n",
      "Epoch 7/100\n",
      "7759/7759 - 2s - loss: 0.7380 - acc: 0.7145 - val_loss: 0.6930 - val_acc: 0.7278\n",
      "Epoch 8/100\n",
      "7759/7759 - 2s - loss: 0.7162 - acc: 0.7214 - val_loss: 0.6800 - val_acc: 0.7367\n",
      "Epoch 9/100\n",
      "7759/7759 - 2s - loss: 0.6888 - acc: 0.7341 - val_loss: 0.6660 - val_acc: 0.7392\n",
      "Epoch 10/100\n",
      "7759/7759 - 2s - loss: 0.6762 - acc: 0.7381 - val_loss: 0.6708 - val_acc: 0.7367\n",
      "Epoch 11/100\n",
      "7759/7759 - 2s - loss: 0.6612 - acc: 0.7451 - val_loss: 0.6551 - val_acc: 0.7468\n",
      "Epoch 12/100\n",
      "7759/7759 - 2s - loss: 0.6381 - acc: 0.7537 - val_loss: 0.6580 - val_acc: 0.7456\n",
      "Epoch 13/100\n",
      "7759/7759 - 2s - loss: 0.6311 - acc: 0.7542 - val_loss: 0.6567 - val_acc: 0.7468\n",
      "Epoch 14/100\n",
      "7759/7759 - 2s - loss: 0.6214 - acc: 0.7523 - val_loss: 0.6475 - val_acc: 0.7519\n",
      "Epoch 15/100\n",
      "7759/7759 - 2s - loss: 0.6186 - acc: 0.7560 - val_loss: 0.6468 - val_acc: 0.7506\n",
      "Epoch 16/100\n",
      "7759/7759 - 2s - loss: 0.6052 - acc: 0.7617 - val_loss: 0.6431 - val_acc: 0.7532\n",
      "Epoch 17/100\n",
      "7759/7759 - 2s - loss: 0.5978 - acc: 0.7661 - val_loss: 0.6483 - val_acc: 0.7506\n",
      "Epoch 18/100\n",
      "7759/7759 - 2s - loss: 0.5977 - acc: 0.7665 - val_loss: 0.6407 - val_acc: 0.7519\n",
      "Epoch 19/100\n",
      "7759/7759 - 2s - loss: 0.5903 - acc: 0.7670 - val_loss: 0.6431 - val_acc: 0.7532\n",
      "Epoch 20/100\n",
      "7759/7759 - 2s - loss: 0.5907 - acc: 0.7639 - val_loss: 0.6347 - val_acc: 0.7595\n",
      "Epoch 21/100\n",
      "7759/7759 - 2s - loss: 0.5800 - acc: 0.7707 - val_loss: 0.6295 - val_acc: 0.7595\n",
      "Epoch 22/100\n",
      "7759/7759 - 2s - loss: 0.5720 - acc: 0.7733 - val_loss: 0.6340 - val_acc: 0.7557\n",
      "Epoch 23/100\n",
      "7759/7759 - 2s - loss: 0.5678 - acc: 0.7737 - val_loss: 0.6228 - val_acc: 0.7671\n",
      "Epoch 24/100\n",
      "7759/7759 - 2s - loss: 0.5661 - acc: 0.7751 - val_loss: 0.6243 - val_acc: 0.7684\n",
      "Epoch 25/100\n",
      "7759/7759 - 2s - loss: 0.5715 - acc: 0.7714 - val_loss: 0.6196 - val_acc: 0.7671\n",
      "Epoch 26/100\n",
      "7759/7759 - 2s - loss: 0.5650 - acc: 0.7714 - val_loss: 0.6229 - val_acc: 0.7658\n",
      "Epoch 27/100\n",
      "7759/7759 - 2s - loss: 0.5687 - acc: 0.7707 - val_loss: 0.6172 - val_acc: 0.7658\n",
      "Epoch 28/100\n",
      "7759/7759 - 2s - loss: 0.5559 - acc: 0.7783 - val_loss: 0.6090 - val_acc: 0.7696\n",
      "Epoch 29/100\n",
      "7759/7759 - 2s - loss: 0.5603 - acc: 0.7773 - val_loss: 0.6118 - val_acc: 0.7684\n",
      "Epoch 30/100\n",
      "7759/7759 - 2s - loss: 0.5531 - acc: 0.7812 - val_loss: 0.6102 - val_acc: 0.7684\n",
      "Epoch 31/100\n",
      "7759/7759 - 2s - loss: 0.5534 - acc: 0.7797 - val_loss: 0.6079 - val_acc: 0.7709\n",
      "Epoch 32/100\n",
      "7759/7759 - 2s - loss: 0.5503 - acc: 0.7806 - val_loss: 0.6020 - val_acc: 0.7696\n",
      "Epoch 33/100\n",
      "7759/7759 - 2s - loss: 0.5430 - acc: 0.7809 - val_loss: 0.6084 - val_acc: 0.7684\n",
      "Epoch 34/100\n",
      "7759/7759 - 2s - loss: 0.5415 - acc: 0.7857 - val_loss: 0.5992 - val_acc: 0.7709\n",
      "Epoch 35/100\n",
      "7759/7759 - 2s - loss: 0.5395 - acc: 0.7876 - val_loss: 0.6021 - val_acc: 0.7709\n",
      "Epoch 36/100\n",
      "7759/7759 - 2s - loss: 0.5373 - acc: 0.7864 - val_loss: 0.5886 - val_acc: 0.7722\n",
      "Epoch 37/100\n",
      "7759/7759 - 2s - loss: 0.5353 - acc: 0.7852 - val_loss: 0.6003 - val_acc: 0.7722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "7759/7759 - 2s - loss: 0.5392 - acc: 0.7858 - val_loss: 0.5824 - val_acc: 0.7722\n",
      "Epoch 39/100\n",
      "7759/7759 - 2s - loss: 0.5255 - acc: 0.7894 - val_loss: 0.5861 - val_acc: 0.7734\n",
      "Epoch 40/100\n",
      "7759/7759 - 2s - loss: 0.5245 - acc: 0.7935 - val_loss: 0.5867 - val_acc: 0.7709\n",
      "Epoch 41/100\n",
      "7759/7759 - 2s - loss: 0.5252 - acc: 0.7919 - val_loss: 0.5966 - val_acc: 0.7722\n",
      "Epoch 42/100\n",
      "7759/7759 - 2s - loss: 0.5246 - acc: 0.7911 - val_loss: 0.5924 - val_acc: 0.7747\n",
      "Epoch 43/100\n",
      "7759/7759 - 2s - loss: 0.5248 - acc: 0.7915 - val_loss: 0.5881 - val_acc: 0.7734\n",
      "Epoch 44/100\n",
      "7759/7759 - 2s - loss: 0.5220 - acc: 0.7920 - val_loss: 0.5945 - val_acc: 0.7709\n",
      "Epoch 45/100\n",
      "7759/7759 - 2s - loss: 0.5218 - acc: 0.7926 - val_loss: 0.5828 - val_acc: 0.7709\n",
      "Epoch 46/100\n",
      "7759/7759 - 2s - loss: 0.5205 - acc: 0.7947 - val_loss: 0.5831 - val_acc: 0.7722\n",
      "Epoch 47/100\n",
      "7759/7759 - 2s - loss: 0.5207 - acc: 0.7908 - val_loss: 0.5815 - val_acc: 0.7747\n",
      "Epoch 48/100\n",
      "7759/7759 - 2s - loss: 0.5163 - acc: 0.7966 - val_loss: 0.5829 - val_acc: 0.7709\n",
      "Epoch 49/100\n",
      "7759/7759 - 2s - loss: 0.5199 - acc: 0.7902 - val_loss: 0.5780 - val_acc: 0.7759\n",
      "Epoch 50/100\n",
      "7759/7759 - 2s - loss: 0.5191 - acc: 0.7920 - val_loss: 0.5715 - val_acc: 0.7734\n",
      "Epoch 51/100\n",
      "7759/7759 - 2s - loss: 0.5136 - acc: 0.7931 - val_loss: 0.5698 - val_acc: 0.7772\n",
      "Epoch 52/100\n",
      "7759/7759 - 2s - loss: 0.5170 - acc: 0.7922 - val_loss: 0.5790 - val_acc: 0.7747\n",
      "Epoch 53/100\n",
      "7759/7759 - 2s - loss: 0.5143 - acc: 0.7943 - val_loss: 0.5721 - val_acc: 0.7759\n",
      "Epoch 54/100\n",
      "7759/7759 - 2s - loss: 0.5116 - acc: 0.7933 - val_loss: 0.5707 - val_acc: 0.7759\n",
      "Epoch 55/100\n",
      "7759/7759 - 2s - loss: 0.5083 - acc: 0.7969 - val_loss: 0.5649 - val_acc: 0.7747\n",
      "Epoch 56/100\n",
      "7759/7759 - 2s - loss: 0.5112 - acc: 0.7949 - val_loss: 0.5703 - val_acc: 0.7772\n",
      "Epoch 57/100\n",
      "7759/7759 - 2s - loss: 0.5063 - acc: 0.7971 - val_loss: 0.5701 - val_acc: 0.7772\n",
      "Epoch 58/100\n",
      "7759/7759 - 2s - loss: 0.5083 - acc: 0.7944 - val_loss: 0.5713 - val_acc: 0.7759\n",
      "Epoch 59/100\n",
      "7759/7759 - 2s - loss: 0.5013 - acc: 0.7958 - val_loss: 0.5656 - val_acc: 0.7759\n",
      "Epoch 60/100\n",
      "7759/7759 - 2s - loss: 0.5053 - acc: 0.8005 - val_loss: 0.5642 - val_acc: 0.7747\n",
      "Epoch 61/100\n",
      "7759/7759 - 2s - loss: 0.4984 - acc: 0.7997 - val_loss: 0.5680 - val_acc: 0.7759\n",
      "Epoch 62/100\n",
      "7759/7759 - 2s - loss: 0.4976 - acc: 0.7995 - val_loss: 0.5664 - val_acc: 0.7759\n",
      "Epoch 63/100\n",
      "7759/7759 - 2s - loss: 0.5020 - acc: 0.7996 - val_loss: 0.5687 - val_acc: 0.7759\n",
      "Epoch 64/100\n",
      "7759/7759 - 2s - loss: 0.5071 - acc: 0.7956 - val_loss: 0.5715 - val_acc: 0.7759\n",
      "Epoch 65/100\n",
      "7759/7759 - 2s - loss: 0.4988 - acc: 0.8020 - val_loss: 0.5623 - val_acc: 0.7785\n",
      "Epoch 66/100\n",
      "7759/7759 - 2s - loss: 0.4965 - acc: 0.8027 - val_loss: 0.5648 - val_acc: 0.7772\n",
      "Epoch 67/100\n",
      "7759/7759 - 2s - loss: 0.4963 - acc: 0.8041 - val_loss: 0.5574 - val_acc: 0.7772\n",
      "Epoch 68/100\n",
      "7759/7759 - 2s - loss: 0.4934 - acc: 0.8058 - val_loss: 0.5664 - val_acc: 0.7772\n",
      "Epoch 69/100\n",
      "7759/7759 - 2s - loss: 0.4987 - acc: 0.8033 - val_loss: 0.5606 - val_acc: 0.7772\n",
      "Epoch 70/100\n",
      "7759/7759 - 2s - loss: 0.4934 - acc: 0.8027 - val_loss: 0.5682 - val_acc: 0.7785\n",
      "Epoch 71/100\n",
      "7759/7759 - 2s - loss: 0.4921 - acc: 0.8059 - val_loss: 0.5607 - val_acc: 0.7785\n",
      "Epoch 72/100\n",
      "7759/7759 - 2s - loss: 0.4885 - acc: 0.8018 - val_loss: 0.5589 - val_acc: 0.7772\n",
      "Epoch 73/100\n",
      "7759/7759 - 2s - loss: 0.4892 - acc: 0.8028 - val_loss: 0.5603 - val_acc: 0.7810\n",
      "Epoch 74/100\n",
      "7759/7759 - 2s - loss: 0.4888 - acc: 0.8042 - val_loss: 0.5600 - val_acc: 0.7785\n",
      "Epoch 75/100\n",
      "7759/7759 - 2s - loss: 0.4908 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7772\n",
      "Epoch 76/100\n",
      "7759/7759 - 2s - loss: 0.4864 - acc: 0.8059 - val_loss: 0.5509 - val_acc: 0.7810\n",
      "Epoch 77/100\n",
      "7759/7759 - 2s - loss: 0.4884 - acc: 0.8082 - val_loss: 0.5595 - val_acc: 0.7785\n",
      "Epoch 78/100\n",
      "7759/7759 - 2s - loss: 0.4829 - acc: 0.8053 - val_loss: 0.5531 - val_acc: 0.7810\n",
      "Epoch 79/100\n",
      "7759/7759 - 2s - loss: 0.4885 - acc: 0.8041 - val_loss: 0.5545 - val_acc: 0.7848\n",
      "Epoch 80/100\n",
      "7759/7759 - 2s - loss: 0.4827 - acc: 0.8051 - val_loss: 0.5499 - val_acc: 0.7835\n",
      "Epoch 81/100\n",
      "7759/7759 - 2s - loss: 0.4853 - acc: 0.8027 - val_loss: 0.5654 - val_acc: 0.7810\n",
      "Epoch 82/100\n",
      "7759/7759 - 2s - loss: 0.4819 - acc: 0.8056 - val_loss: 0.5399 - val_acc: 0.7848\n",
      "Epoch 83/100\n",
      "7759/7759 - 2s - loss: 0.4828 - acc: 0.8058 - val_loss: 0.5645 - val_acc: 0.7797\n",
      "Epoch 84/100\n",
      "7759/7759 - 2s - loss: 0.4840 - acc: 0.8072 - val_loss: 0.5493 - val_acc: 0.7835\n",
      "Epoch 85/100\n",
      "7759/7759 - 2s - loss: 0.4829 - acc: 0.8064 - val_loss: 0.5496 - val_acc: 0.7848\n",
      "Epoch 86/100\n",
      "7759/7759 - 2s - loss: 0.4812 - acc: 0.8121 - val_loss: 0.5575 - val_acc: 0.7835\n",
      "Epoch 87/100\n",
      "7759/7759 - 2s - loss: 0.4760 - acc: 0.8103 - val_loss: 0.5504 - val_acc: 0.7835\n",
      "Epoch 88/100\n",
      "7759/7759 - 2s - loss: 0.4799 - acc: 0.8078 - val_loss: 0.5578 - val_acc: 0.7835\n",
      "Epoch 89/100\n",
      "7759/7759 - 2s - loss: 0.4753 - acc: 0.8134 - val_loss: 0.5537 - val_acc: 0.7835\n",
      "Epoch 90/100\n",
      "7759/7759 - 2s - loss: 0.4740 - acc: 0.8074 - val_loss: 0.5512 - val_acc: 0.7848\n",
      "Epoch 91/100\n",
      "7759/7759 - 2s - loss: 0.4727 - acc: 0.8140 - val_loss: 0.5622 - val_acc: 0.7823\n",
      "Epoch 92/100\n",
      "7759/7759 - 2s - loss: 0.4753 - acc: 0.8102 - val_loss: 0.5473 - val_acc: 0.7848\n",
      "Epoch 93/100\n",
      "7759/7759 - 2s - loss: 0.4783 - acc: 0.8086 - val_loss: 0.5583 - val_acc: 0.7848\n",
      "Epoch 94/100\n",
      "7759/7759 - 2s - loss: 0.4698 - acc: 0.8111 - val_loss: 0.5486 - val_acc: 0.7848\n",
      "Epoch 95/100\n",
      "7759/7759 - 2s - loss: 0.4741 - acc: 0.8080 - val_loss: 0.5519 - val_acc: 0.7823\n",
      "Epoch 96/100\n",
      "7759/7759 - 2s - loss: 0.4681 - acc: 0.8118 - val_loss: 0.5494 - val_acc: 0.7835\n",
      "Epoch 97/100\n",
      "7759/7759 - 2s - loss: 0.4707 - acc: 0.8109 - val_loss: 0.5506 - val_acc: 0.7848\n",
      "Epoch 98/100\n",
      "7759/7759 - 2s - loss: 0.4685 - acc: 0.8148 - val_loss: 0.5517 - val_acc: 0.7861\n",
      "Epoch 99/100\n",
      "7759/7759 - 2s - loss: 0.4704 - acc: 0.8148 - val_loss: 0.5541 - val_acc: 0.7861\n",
      "Epoch 100/100\n",
      "7759/7759 - 2s - loss: 0.4677 - acc: 0.8121 - val_loss: 0.5483 - val_acc: 0.7861\n",
      "Evaluate 0.78607595\n",
      "Fold # 3    Train: (7789, 5, 90)   Test: (760, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7789 samples, validate on 760 samples\n",
      "Epoch 1/100\n",
      "7789/7789 - 5s - loss: 1.5221 - acc: 0.3199 - val_loss: 1.3335 - val_acc: 0.6355\n",
      "Epoch 2/100\n",
      "7789/7789 - 2s - loss: 1.1434 - acc: 0.5680 - val_loss: 1.1292 - val_acc: 0.5934\n",
      "Epoch 3/100\n",
      "7789/7789 - 2s - loss: 0.9589 - acc: 0.6424 - val_loss: 1.0653 - val_acc: 0.5645\n",
      "Epoch 4/100\n",
      "7789/7789 - 2s - loss: 0.8647 - acc: 0.6760 - val_loss: 1.0409 - val_acc: 0.5434\n",
      "Epoch 5/100\n",
      "7789/7789 - 2s - loss: 0.8047 - acc: 0.6971 - val_loss: 1.0193 - val_acc: 0.5645\n",
      "Epoch 6/100\n",
      "7789/7789 - 2s - loss: 0.7594 - acc: 0.7163 - val_loss: 1.0275 - val_acc: 0.5711\n",
      "Epoch 7/100\n",
      "7789/7789 - 2s - loss: 0.7261 - acc: 0.7214 - val_loss: 1.0425 - val_acc: 0.5632\n",
      "Epoch 8/100\n",
      "7789/7789 - 2s - loss: 0.6989 - acc: 0.7349 - val_loss: 1.0587 - val_acc: 0.5592\n",
      "Epoch 9/100\n",
      "7789/7789 - 2s - loss: 0.6718 - acc: 0.7408 - val_loss: 1.0727 - val_acc: 0.5500\n",
      "Epoch 10/100\n",
      "7789/7789 - 2s - loss: 0.6542 - acc: 0.7450 - val_loss: 1.1011 - val_acc: 0.5434\n",
      "Epoch 11/100\n",
      "7789/7789 - 2s - loss: 0.6407 - acc: 0.7500 - val_loss: 1.1286 - val_acc: 0.5487\n",
      "Epoch 12/100\n",
      "7789/7789 - 2s - loss: 0.6213 - acc: 0.7571 - val_loss: 1.1484 - val_acc: 0.5408\n",
      "Epoch 13/100\n",
      "7789/7789 - 2s - loss: 0.6112 - acc: 0.7636 - val_loss: 1.1688 - val_acc: 0.5408\n",
      "Epoch 14/100\n",
      "7789/7789 - 2s - loss: 0.5943 - acc: 0.7698 - val_loss: 1.1908 - val_acc: 0.5382\n",
      "Epoch 15/100\n",
      "7789/7789 - 2s - loss: 0.5951 - acc: 0.7677 - val_loss: 1.1985 - val_acc: 0.5395\n",
      "Epoch 16/100\n",
      "7789/7789 - 2s - loss: 0.5823 - acc: 0.7737 - val_loss: 1.2113 - val_acc: 0.5316\n",
      "Epoch 17/100\n",
      "7789/7789 - 2s - loss: 0.5820 - acc: 0.7708 - val_loss: 1.2471 - val_acc: 0.5250\n",
      "Epoch 18/100\n",
      "7789/7789 - 2s - loss: 0.5723 - acc: 0.7771 - val_loss: 1.2401 - val_acc: 0.5303\n",
      "Epoch 19/100\n",
      "7789/7789 - 2s - loss: 0.5700 - acc: 0.7755 - val_loss: 1.2363 - val_acc: 0.5342\n",
      "Epoch 20/100\n",
      "7789/7789 - 2s - loss: 0.5660 - acc: 0.7719 - val_loss: 1.2596 - val_acc: 0.5276\n",
      "Epoch 21/100\n",
      "7789/7789 - 2s - loss: 0.5600 - acc: 0.7779 - val_loss: 1.2610 - val_acc: 0.5316\n",
      "Epoch 22/100\n",
      "7789/7789 - 2s - loss: 0.5549 - acc: 0.7805 - val_loss: 1.2679 - val_acc: 0.5329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "7789/7789 - 2s - loss: 0.5474 - acc: 0.7829 - val_loss: 1.2540 - val_acc: 0.5434\n",
      "Epoch 24/100\n",
      "7789/7789 - 2s - loss: 0.5521 - acc: 0.7793 - val_loss: 1.2758 - val_acc: 0.5368\n",
      "Epoch 25/100\n",
      "7789/7789 - 2s - loss: 0.5476 - acc: 0.7846 - val_loss: 1.2534 - val_acc: 0.5421\n",
      "Epoch 26/100\n",
      "7789/7789 - 2s - loss: 0.5441 - acc: 0.7772 - val_loss: 1.2625 - val_acc: 0.5434\n",
      "Epoch 27/100\n",
      "7789/7789 - 2s - loss: 0.5449 - acc: 0.7844 - val_loss: 1.2886 - val_acc: 0.5395\n",
      "Epoch 28/100\n",
      "7789/7789 - 2s - loss: 0.5423 - acc: 0.7821 - val_loss: 1.2644 - val_acc: 0.5434\n",
      "Epoch 29/100\n",
      "7789/7789 - 2s - loss: 0.5405 - acc: 0.7866 - val_loss: 1.2896 - val_acc: 0.5395\n",
      "Epoch 30/100\n",
      "7789/7789 - 2s - loss: 0.5350 - acc: 0.7864 - val_loss: 1.2853 - val_acc: 0.5434\n",
      "Epoch 31/100\n",
      "7789/7789 - 2s - loss: 0.5349 - acc: 0.7834 - val_loss: 1.2754 - val_acc: 0.5461\n",
      "Epoch 32/100\n",
      "7789/7789 - 2s - loss: 0.5236 - acc: 0.7941 - val_loss: 1.2782 - val_acc: 0.5447\n",
      "Epoch 33/100\n",
      "7789/7789 - 2s - loss: 0.5244 - acc: 0.7882 - val_loss: 1.2724 - val_acc: 0.5474\n",
      "Epoch 34/100\n",
      "7789/7789 - 2s - loss: 0.5271 - acc: 0.7902 - val_loss: 1.2856 - val_acc: 0.5421\n",
      "Epoch 35/100\n",
      "7789/7789 - 2s - loss: 0.5209 - acc: 0.7920 - val_loss: 1.2836 - val_acc: 0.5539\n",
      "Epoch 36/100\n",
      "7789/7789 - 2s - loss: 0.5205 - acc: 0.7963 - val_loss: 1.3106 - val_acc: 0.5474\n",
      "Epoch 37/100\n",
      "7789/7789 - 2s - loss: 0.5179 - acc: 0.7956 - val_loss: 1.2800 - val_acc: 0.5487\n",
      "Epoch 38/100\n",
      "7789/7789 - 2s - loss: 0.5204 - acc: 0.7954 - val_loss: 1.3039 - val_acc: 0.5513\n",
      "Epoch 39/100\n",
      "7789/7789 - 2s - loss: 0.5160 - acc: 0.7948 - val_loss: 1.2967 - val_acc: 0.5500\n",
      "Epoch 40/100\n",
      "7789/7789 - 2s - loss: 0.5117 - acc: 0.7984 - val_loss: 1.2979 - val_acc: 0.5526\n",
      "Epoch 41/100\n",
      "7789/7789 - 2s - loss: 0.5111 - acc: 0.7989 - val_loss: 1.3093 - val_acc: 0.5526\n",
      "Epoch 42/100\n",
      "7789/7789 - 2s - loss: 0.5095 - acc: 0.7952 - val_loss: 1.3045 - val_acc: 0.5487\n",
      "Epoch 43/100\n",
      "7789/7789 - 2s - loss: 0.5059 - acc: 0.7977 - val_loss: 1.2979 - val_acc: 0.5487\n",
      "Epoch 44/100\n",
      "7789/7789 - 2s - loss: 0.5076 - acc: 0.7984 - val_loss: 1.3227 - val_acc: 0.5513\n",
      "Epoch 45/100\n",
      "7789/7789 - 2s - loss: 0.5057 - acc: 0.8015 - val_loss: 1.3027 - val_acc: 0.5539\n",
      "Epoch 46/100\n",
      "7789/7789 - 2s - loss: 0.5009 - acc: 0.8029 - val_loss: 1.3066 - val_acc: 0.5566\n",
      "Epoch 47/100\n",
      "7789/7789 - 2s - loss: 0.5060 - acc: 0.7982 - val_loss: 1.2744 - val_acc: 0.5579\n",
      "Epoch 48/100\n",
      "7789/7789 - 2s - loss: 0.5058 - acc: 0.7977 - val_loss: 1.3228 - val_acc: 0.5500\n",
      "Epoch 49/100\n",
      "7789/7789 - 2s - loss: 0.4989 - acc: 0.7980 - val_loss: 1.3137 - val_acc: 0.5579\n",
      "Epoch 50/100\n",
      "7789/7789 - 2s - loss: 0.4982 - acc: 0.8009 - val_loss: 1.3429 - val_acc: 0.5500\n",
      "Epoch 51/100\n",
      "7789/7789 - 2s - loss: 0.4953 - acc: 0.8020 - val_loss: 1.3457 - val_acc: 0.5500\n",
      "Epoch 52/100\n",
      "7789/7789 - 2s - loss: 0.4964 - acc: 0.8009 - val_loss: 1.3168 - val_acc: 0.5513\n",
      "Epoch 53/100\n",
      "7789/7789 - 2s - loss: 0.4944 - acc: 0.8033 - val_loss: 1.3555 - val_acc: 0.5513\n",
      "Epoch 54/100\n",
      "7789/7789 - 2s - loss: 0.4934 - acc: 0.8040 - val_loss: 1.3302 - val_acc: 0.5539\n",
      "Epoch 55/100\n",
      "7789/7789 - 2s - loss: 0.4876 - acc: 0.8105 - val_loss: 1.3255 - val_acc: 0.5513\n",
      "Epoch 56/100\n",
      "7789/7789 - 2s - loss: 0.4884 - acc: 0.8079 - val_loss: 1.3317 - val_acc: 0.5526\n",
      "Epoch 57/100\n",
      "7789/7789 - 2s - loss: 0.4901 - acc: 0.8023 - val_loss: 1.3389 - val_acc: 0.5539\n",
      "Epoch 58/100\n",
      "7789/7789 - 2s - loss: 0.4917 - acc: 0.8041 - val_loss: 1.3262 - val_acc: 0.5553\n",
      "Epoch 59/100\n",
      "7789/7789 - 2s - loss: 0.4903 - acc: 0.8019 - val_loss: 1.3145 - val_acc: 0.5553\n",
      "Epoch 60/100\n",
      "7789/7789 - 2s - loss: 0.4870 - acc: 0.8068 - val_loss: 1.3415 - val_acc: 0.5526\n",
      "Epoch 61/100\n",
      "7789/7789 - 2s - loss: 0.4817 - acc: 0.8078 - val_loss: 1.3622 - val_acc: 0.5487\n",
      "Epoch 62/100\n",
      "7789/7789 - 2s - loss: 0.4818 - acc: 0.8065 - val_loss: 1.3409 - val_acc: 0.5526\n",
      "Epoch 63/100\n",
      "7789/7789 - 2s - loss: 0.4882 - acc: 0.8029 - val_loss: 1.3329 - val_acc: 0.5566\n",
      "Epoch 64/100\n",
      "7789/7789 - 2s - loss: 0.4827 - acc: 0.8091 - val_loss: 1.3374 - val_acc: 0.5566\n",
      "Epoch 65/100\n",
      "7789/7789 - 2s - loss: 0.4769 - acc: 0.8072 - val_loss: 1.3514 - val_acc: 0.5553\n",
      "Epoch 66/100\n",
      "7789/7789 - 2s - loss: 0.4812 - acc: 0.8056 - val_loss: 1.3217 - val_acc: 0.5605\n",
      "Epoch 67/100\n",
      "7789/7789 - 2s - loss: 0.4810 - acc: 0.8059 - val_loss: 1.3478 - val_acc: 0.5566\n",
      "Epoch 68/100\n",
      "7789/7789 - 2s - loss: 0.4787 - acc: 0.8102 - val_loss: 1.3398 - val_acc: 0.5553\n",
      "Epoch 69/100\n",
      "7789/7789 - 2s - loss: 0.4818 - acc: 0.8090 - val_loss: 1.3612 - val_acc: 0.5553\n",
      "Epoch 70/100\n",
      "7789/7789 - 2s - loss: 0.4765 - acc: 0.8093 - val_loss: 1.3446 - val_acc: 0.5566\n",
      "Epoch 71/100\n",
      "7789/7789 - 2s - loss: 0.4761 - acc: 0.8133 - val_loss: 1.3705 - val_acc: 0.5526\n",
      "Epoch 72/100\n",
      "7789/7789 - 2s - loss: 0.4763 - acc: 0.8104 - val_loss: 1.3724 - val_acc: 0.5500\n",
      "Epoch 73/100\n",
      "7789/7789 - 2s - loss: 0.4770 - acc: 0.8099 - val_loss: 1.3577 - val_acc: 0.5605\n",
      "Epoch 74/100\n",
      "7789/7789 - 2s - loss: 0.4742 - acc: 0.8097 - val_loss: 1.3579 - val_acc: 0.5579\n",
      "Epoch 75/100\n",
      "7789/7789 - 2s - loss: 0.4742 - acc: 0.8153 - val_loss: 1.3398 - val_acc: 0.5579\n",
      "Epoch 76/100\n",
      "7789/7789 - 2s - loss: 0.4736 - acc: 0.8129 - val_loss: 1.3610 - val_acc: 0.5513\n",
      "Epoch 77/100\n",
      "7789/7789 - 2s - loss: 0.4692 - acc: 0.8149 - val_loss: 1.3536 - val_acc: 0.5592\n",
      "Epoch 78/100\n",
      "7789/7789 - 2s - loss: 0.4692 - acc: 0.8118 - val_loss: 1.3676 - val_acc: 0.5526\n",
      "Epoch 79/100\n",
      "7789/7789 - 2s - loss: 0.4723 - acc: 0.8100 - val_loss: 1.3363 - val_acc: 0.5592\n",
      "Epoch 80/100\n",
      "7789/7789 - 2s - loss: 0.4692 - acc: 0.8110 - val_loss: 1.3656 - val_acc: 0.5553\n",
      "Epoch 81/100\n",
      "7789/7789 - 2s - loss: 0.4742 - acc: 0.8104 - val_loss: 1.3733 - val_acc: 0.5526\n",
      "Epoch 82/100\n",
      "7789/7789 - 2s - loss: 0.4632 - acc: 0.8164 - val_loss: 1.3704 - val_acc: 0.5500\n",
      "Epoch 83/100\n",
      "7789/7789 - 2s - loss: 0.4639 - acc: 0.8120 - val_loss: 1.3570 - val_acc: 0.5526\n",
      "Epoch 84/100\n",
      "7789/7789 - 2s - loss: 0.4630 - acc: 0.8156 - val_loss: 1.3594 - val_acc: 0.5553\n",
      "Epoch 85/100\n",
      "7789/7789 - 2s - loss: 0.4624 - acc: 0.8168 - val_loss: 1.3772 - val_acc: 0.5526\n",
      "Epoch 86/100\n",
      "7789/7789 - 2s - loss: 0.4657 - acc: 0.8169 - val_loss: 1.3739 - val_acc: 0.5579\n",
      "Epoch 87/100\n",
      "7789/7789 - 2s - loss: 0.4672 - acc: 0.8123 - val_loss: 1.3823 - val_acc: 0.5513\n",
      "Epoch 88/100\n",
      "7789/7789 - 2s - loss: 0.4632 - acc: 0.8136 - val_loss: 1.3723 - val_acc: 0.5539\n",
      "Epoch 89/100\n",
      "7789/7789 - 2s - loss: 0.4632 - acc: 0.8169 - val_loss: 1.3844 - val_acc: 0.5553\n",
      "Epoch 90/100\n",
      "7789/7789 - 2s - loss: 0.4592 - acc: 0.8146 - val_loss: 1.3687 - val_acc: 0.5553\n",
      "Epoch 91/100\n",
      "7789/7789 - 2s - loss: 0.4586 - acc: 0.8186 - val_loss: 1.3857 - val_acc: 0.5539\n",
      "Epoch 92/100\n",
      "7789/7789 - 2s - loss: 0.4622 - acc: 0.8127 - val_loss: 1.3807 - val_acc: 0.5539\n",
      "Epoch 93/100\n",
      "7789/7789 - 2s - loss: 0.4546 - acc: 0.8201 - val_loss: 1.4016 - val_acc: 0.5500\n",
      "Epoch 94/100\n",
      "7789/7789 - 2s - loss: 0.4611 - acc: 0.8153 - val_loss: 1.3865 - val_acc: 0.5487\n",
      "Epoch 95/100\n",
      "7789/7789 - 2s - loss: 0.4526 - acc: 0.8191 - val_loss: 1.3828 - val_acc: 0.5539\n",
      "Epoch 96/100\n",
      "7789/7789 - 2s - loss: 0.4549 - acc: 0.8201 - val_loss: 1.3825 - val_acc: 0.5553\n",
      "Epoch 97/100\n",
      "7789/7789 - 2s - loss: 0.4540 - acc: 0.8179 - val_loss: 1.3826 - val_acc: 0.5526\n",
      "Epoch 98/100\n",
      "7789/7789 - 2s - loss: 0.4557 - acc: 0.8170 - val_loss: 1.3592 - val_acc: 0.5605\n",
      "Epoch 99/100\n",
      "7789/7789 - 2s - loss: 0.4561 - acc: 0.8165 - val_loss: 1.3767 - val_acc: 0.5592\n",
      "Epoch 100/100\n",
      "7789/7789 - 2s - loss: 0.4526 - acc: 0.8210 - val_loss: 1.3622 - val_acc: 0.5592\n",
      "Evaluate 0.6355263\n",
      "Fold # 4    Train: (7639, 5, 90)   Test: (910, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7639 samples, validate on 910 samples\n",
      "Epoch 1/100\n",
      "7639/7639 - 5s - loss: 1.5088 - acc: 0.3243 - val_loss: 1.1347 - val_acc: 0.7857\n",
      "Epoch 2/100\n",
      "7639/7639 - 3s - loss: 1.1399 - acc: 0.5547 - val_loss: 0.8702 - val_acc: 0.7747\n",
      "Epoch 3/100\n",
      "7639/7639 - 3s - loss: 0.9599 - acc: 0.6339 - val_loss: 0.8231 - val_acc: 0.7176\n",
      "Epoch 4/100\n",
      "7639/7639 - 3s - loss: 0.8698 - acc: 0.6671 - val_loss: 0.7809 - val_acc: 0.7143\n",
      "Epoch 5/100\n",
      "7639/7639 - 3s - loss: 0.8045 - acc: 0.6909 - val_loss: 0.7472 - val_acc: 0.7286\n",
      "Epoch 6/100\n",
      "7639/7639 - 3s - loss: 0.7649 - acc: 0.7031 - val_loss: 0.7297 - val_acc: 0.7363\n",
      "Epoch 7/100\n",
      "7639/7639 - 3s - loss: 0.7305 - acc: 0.7166 - val_loss: 0.7069 - val_acc: 0.7462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "7639/7639 - 3s - loss: 0.7139 - acc: 0.7199 - val_loss: 0.6932 - val_acc: 0.7473\n",
      "Epoch 9/100\n",
      "7639/7639 - 3s - loss: 0.6913 - acc: 0.7297 - val_loss: 0.6802 - val_acc: 0.7495\n",
      "Epoch 10/100\n",
      "7639/7639 - 3s - loss: 0.6729 - acc: 0.7353 - val_loss: 0.6715 - val_acc: 0.7560\n",
      "Epoch 11/100\n",
      "7639/7639 - 3s - loss: 0.6586 - acc: 0.7375 - val_loss: 0.6554 - val_acc: 0.7659\n",
      "Epoch 12/100\n",
      "7639/7639 - 3s - loss: 0.6470 - acc: 0.7408 - val_loss: 0.6521 - val_acc: 0.7637\n",
      "Epoch 13/100\n",
      "7639/7639 - 3s - loss: 0.6352 - acc: 0.7488 - val_loss: 0.6292 - val_acc: 0.7736\n",
      "Epoch 14/100\n",
      "7639/7639 - 3s - loss: 0.6203 - acc: 0.7518 - val_loss: 0.6354 - val_acc: 0.7736\n",
      "Epoch 15/100\n",
      "7639/7639 - 3s - loss: 0.6150 - acc: 0.7547 - val_loss: 0.6297 - val_acc: 0.7692\n",
      "Epoch 16/100\n",
      "7639/7639 - 3s - loss: 0.6117 - acc: 0.7552 - val_loss: 0.6082 - val_acc: 0.7736\n",
      "Epoch 17/100\n",
      "7639/7639 - 3s - loss: 0.6055 - acc: 0.7587 - val_loss: 0.6115 - val_acc: 0.7714\n",
      "Epoch 18/100\n",
      "7639/7639 - 3s - loss: 0.6021 - acc: 0.7619 - val_loss: 0.6130 - val_acc: 0.7725\n",
      "Epoch 19/100\n",
      "7639/7639 - 3s - loss: 0.5970 - acc: 0.7581 - val_loss: 0.6032 - val_acc: 0.7769\n",
      "Epoch 20/100\n",
      "7639/7639 - 3s - loss: 0.5974 - acc: 0.7615 - val_loss: 0.6052 - val_acc: 0.7725\n",
      "Epoch 21/100\n",
      "7639/7639 - 3s - loss: 0.5850 - acc: 0.7669 - val_loss: 0.6016 - val_acc: 0.7725\n",
      "Epoch 22/100\n",
      "7639/7639 - 3s - loss: 0.5825 - acc: 0.7631 - val_loss: 0.6027 - val_acc: 0.7714\n",
      "Epoch 23/100\n",
      "7639/7639 - 3s - loss: 0.5816 - acc: 0.7650 - val_loss: 0.6001 - val_acc: 0.7714\n",
      "Epoch 24/100\n",
      "7639/7639 - 3s - loss: 0.5764 - acc: 0.7669 - val_loss: 0.5979 - val_acc: 0.7725\n",
      "Epoch 25/100\n",
      "7639/7639 - 3s - loss: 0.5726 - acc: 0.7704 - val_loss: 0.5968 - val_acc: 0.7725\n",
      "Epoch 26/100\n",
      "7639/7639 - 3s - loss: 0.5678 - acc: 0.7705 - val_loss: 0.5976 - val_acc: 0.7725\n",
      "Epoch 27/100\n",
      "7639/7639 - 3s - loss: 0.5686 - acc: 0.7700 - val_loss: 0.5978 - val_acc: 0.7736\n",
      "Epoch 28/100\n",
      "7639/7639 - 3s - loss: 0.5700 - acc: 0.7752 - val_loss: 0.5877 - val_acc: 0.7758\n",
      "Epoch 29/100\n",
      "7639/7639 - 3s - loss: 0.5589 - acc: 0.7756 - val_loss: 0.5945 - val_acc: 0.7747\n",
      "Epoch 30/100\n",
      "7639/7639 - 3s - loss: 0.5574 - acc: 0.7764 - val_loss: 0.5934 - val_acc: 0.7791\n",
      "Epoch 31/100\n",
      "7639/7639 - 3s - loss: 0.5545 - acc: 0.7746 - val_loss: 0.5912 - val_acc: 0.7780\n",
      "Epoch 32/100\n",
      "7639/7639 - 3s - loss: 0.5542 - acc: 0.7752 - val_loss: 0.5918 - val_acc: 0.7802\n",
      "Epoch 33/100\n",
      "7639/7639 - 3s - loss: 0.5520 - acc: 0.7790 - val_loss: 0.5874 - val_acc: 0.7813\n",
      "Epoch 34/100\n",
      "7639/7639 - 3s - loss: 0.5479 - acc: 0.7806 - val_loss: 0.5838 - val_acc: 0.7824\n",
      "Epoch 35/100\n",
      "7639/7639 - 3s - loss: 0.5421 - acc: 0.7822 - val_loss: 0.5834 - val_acc: 0.7857\n",
      "Epoch 36/100\n",
      "7639/7639 - 3s - loss: 0.5445 - acc: 0.7779 - val_loss: 0.5793 - val_acc: 0.7813\n",
      "Epoch 37/100\n",
      "7639/7639 - 3s - loss: 0.5499 - acc: 0.7794 - val_loss: 0.5798 - val_acc: 0.7857\n",
      "Epoch 38/100\n",
      "7639/7639 - 3s - loss: 0.5470 - acc: 0.7780 - val_loss: 0.5846 - val_acc: 0.7835\n",
      "Epoch 39/100\n",
      "7639/7639 - 3s - loss: 0.5430 - acc: 0.7826 - val_loss: 0.5725 - val_acc: 0.7890\n",
      "Epoch 40/100\n",
      "7639/7639 - 3s - loss: 0.5375 - acc: 0.7848 - val_loss: 0.5837 - val_acc: 0.7857\n",
      "Epoch 41/100\n",
      "7639/7639 - 3s - loss: 0.5372 - acc: 0.7852 - val_loss: 0.5766 - val_acc: 0.7835\n",
      "Epoch 42/100\n",
      "7639/7639 - 3s - loss: 0.5313 - acc: 0.7830 - val_loss: 0.5780 - val_acc: 0.7857\n",
      "Epoch 43/100\n",
      "7639/7639 - 3s - loss: 0.5305 - acc: 0.7853 - val_loss: 0.5688 - val_acc: 0.7857\n",
      "Epoch 44/100\n",
      "7639/7639 - 3s - loss: 0.5287 - acc: 0.7904 - val_loss: 0.5760 - val_acc: 0.7879\n",
      "Epoch 45/100\n",
      "7639/7639 - 3s - loss: 0.5247 - acc: 0.7886 - val_loss: 0.5725 - val_acc: 0.7868\n",
      "Epoch 46/100\n",
      "7639/7639 - 3s - loss: 0.5270 - acc: 0.7871 - val_loss: 0.5800 - val_acc: 0.7857\n",
      "Epoch 47/100\n",
      "7639/7639 - 3s - loss: 0.5301 - acc: 0.7871 - val_loss: 0.5761 - val_acc: 0.7890\n",
      "Epoch 48/100\n",
      "7639/7639 - 3s - loss: 0.5257 - acc: 0.7926 - val_loss: 0.5673 - val_acc: 0.7912\n",
      "Epoch 49/100\n",
      "7639/7639 - 3s - loss: 0.5178 - acc: 0.7928 - val_loss: 0.5799 - val_acc: 0.7879\n",
      "Epoch 50/100\n",
      "7639/7639 - 3s - loss: 0.5211 - acc: 0.7892 - val_loss: 0.5620 - val_acc: 0.7934\n",
      "Epoch 51/100\n",
      "7639/7639 - 3s - loss: 0.5211 - acc: 0.7908 - val_loss: 0.5739 - val_acc: 0.7868\n",
      "Epoch 52/100\n",
      "7639/7639 - 3s - loss: 0.5204 - acc: 0.7890 - val_loss: 0.5642 - val_acc: 0.7901\n",
      "Epoch 53/100\n",
      "7639/7639 - 3s - loss: 0.5198 - acc: 0.7960 - val_loss: 0.5673 - val_acc: 0.7912\n",
      "Epoch 54/100\n",
      "7639/7639 - 3s - loss: 0.5194 - acc: 0.7907 - val_loss: 0.5626 - val_acc: 0.7923\n",
      "Epoch 55/100\n",
      "7639/7639 - 3s - loss: 0.5132 - acc: 0.7954 - val_loss: 0.5682 - val_acc: 0.7901\n",
      "Epoch 56/100\n",
      "7639/7639 - 3s - loss: 0.5193 - acc: 0.7890 - val_loss: 0.5605 - val_acc: 0.7912\n",
      "Epoch 57/100\n",
      "7639/7639 - 3s - loss: 0.5163 - acc: 0.7913 - val_loss: 0.5667 - val_acc: 0.7890\n",
      "Epoch 58/100\n",
      "7639/7639 - 3s - loss: 0.5106 - acc: 0.7930 - val_loss: 0.5685 - val_acc: 0.7912\n",
      "Epoch 59/100\n",
      "7639/7639 - 3s - loss: 0.5112 - acc: 0.7950 - val_loss: 0.5663 - val_acc: 0.7901\n",
      "Epoch 60/100\n",
      "7639/7639 - 3s - loss: 0.5108 - acc: 0.7907 - val_loss: 0.5667 - val_acc: 0.7901\n",
      "Epoch 61/100\n",
      "7639/7639 - 3s - loss: 0.5083 - acc: 0.7968 - val_loss: 0.5619 - val_acc: 0.7945\n",
      "Epoch 62/100\n",
      "7639/7639 - 3s - loss: 0.5110 - acc: 0.7963 - val_loss: 0.5591 - val_acc: 0.7956\n",
      "Epoch 63/100\n",
      "7639/7639 - 3s - loss: 0.5050 - acc: 0.7951 - val_loss: 0.5626 - val_acc: 0.7945\n",
      "Epoch 64/100\n",
      "7639/7639 - 3s - loss: 0.5031 - acc: 0.7960 - val_loss: 0.5536 - val_acc: 0.7989\n",
      "Epoch 65/100\n",
      "7639/7639 - 3s - loss: 0.5035 - acc: 0.7940 - val_loss: 0.5600 - val_acc: 0.7934\n",
      "Epoch 66/100\n",
      "7639/7639 - 3s - loss: 0.5118 - acc: 0.7933 - val_loss: 0.5577 - val_acc: 0.7956\n",
      "Epoch 67/100\n",
      "7639/7639 - 3s - loss: 0.5011 - acc: 0.7989 - val_loss: 0.5551 - val_acc: 0.7978\n",
      "Epoch 68/100\n",
      "7639/7639 - 3s - loss: 0.5022 - acc: 0.7957 - val_loss: 0.5605 - val_acc: 0.7956\n",
      "Epoch 69/100\n",
      "7639/7639 - 3s - loss: 0.5014 - acc: 0.7980 - val_loss: 0.5519 - val_acc: 0.8011\n",
      "Epoch 70/100\n",
      "7639/7639 - 3s - loss: 0.5024 - acc: 0.7987 - val_loss: 0.5636 - val_acc: 0.7945\n",
      "Epoch 71/100\n",
      "7639/7639 - 3s - loss: 0.5017 - acc: 0.8006 - val_loss: 0.5567 - val_acc: 0.7923\n",
      "Epoch 72/100\n",
      "7639/7639 - 3s - loss: 0.4917 - acc: 0.8038 - val_loss: 0.5579 - val_acc: 0.7945\n",
      "Epoch 73/100\n",
      "7639/7639 - 3s - loss: 0.4958 - acc: 0.7974 - val_loss: 0.5504 - val_acc: 0.7978\n",
      "Epoch 74/100\n",
      "7639/7639 - 3s - loss: 0.4966 - acc: 0.8015 - val_loss: 0.5552 - val_acc: 0.7989\n",
      "Epoch 75/100\n",
      "7639/7639 - 3s - loss: 0.4937 - acc: 0.8004 - val_loss: 0.5549 - val_acc: 0.7989\n",
      "Epoch 76/100\n",
      "7639/7639 - 3s - loss: 0.4926 - acc: 0.8010 - val_loss: 0.5569 - val_acc: 0.7945\n",
      "Epoch 77/100\n",
      "7639/7639 - 3s - loss: 0.4883 - acc: 0.8042 - val_loss: 0.5591 - val_acc: 0.7934\n",
      "Epoch 78/100\n",
      "7639/7639 - 3s - loss: 0.4912 - acc: 0.8026 - val_loss: 0.5588 - val_acc: 0.7956\n",
      "Epoch 79/100\n",
      "7639/7639 - 3s - loss: 0.4901 - acc: 0.8029 - val_loss: 0.5556 - val_acc: 0.7956\n",
      "Epoch 80/100\n",
      "7639/7639 - 3s - loss: 0.4888 - acc: 0.8051 - val_loss: 0.5518 - val_acc: 0.7989\n",
      "Epoch 81/100\n",
      "7639/7639 - 3s - loss: 0.4889 - acc: 0.8002 - val_loss: 0.5576 - val_acc: 0.7934\n",
      "Epoch 82/100\n",
      "7639/7639 - 3s - loss: 0.4850 - acc: 0.8057 - val_loss: 0.5560 - val_acc: 0.7934\n",
      "Epoch 83/100\n",
      "7639/7639 - 3s - loss: 0.4850 - acc: 0.8057 - val_loss: 0.5551 - val_acc: 0.7967\n",
      "Epoch 84/100\n",
      "7639/7639 - 3s - loss: 0.4882 - acc: 0.8017 - val_loss: 0.5496 - val_acc: 0.7978\n",
      "Epoch 85/100\n",
      "7639/7639 - 3s - loss: 0.4860 - acc: 0.8048 - val_loss: 0.5448 - val_acc: 0.7978\n",
      "Epoch 86/100\n",
      "7639/7639 - 3s - loss: 0.4806 - acc: 0.8098 - val_loss: 0.5457 - val_acc: 0.8011\n",
      "Epoch 87/100\n",
      "7639/7639 - 3s - loss: 0.4863 - acc: 0.8059 - val_loss: 0.5470 - val_acc: 0.7978\n",
      "Epoch 88/100\n",
      "7639/7639 - 3s - loss: 0.4836 - acc: 0.8042 - val_loss: 0.5470 - val_acc: 0.7989\n",
      "Epoch 89/100\n",
      "7639/7639 - 3s - loss: 0.4807 - acc: 0.8086 - val_loss: 0.5375 - val_acc: 0.8022\n",
      "Epoch 90/100\n",
      "7639/7639 - 3s - loss: 0.4877 - acc: 0.8021 - val_loss: 0.5476 - val_acc: 0.7978\n",
      "Epoch 91/100\n",
      "7639/7639 - 3s - loss: 0.4856 - acc: 0.8034 - val_loss: 0.5398 - val_acc: 0.8022\n",
      "Epoch 92/100\n",
      "7639/7639 - 3s - loss: 0.4820 - acc: 0.8076 - val_loss: 0.5438 - val_acc: 0.7978\n",
      "Epoch 93/100\n",
      "7639/7639 - 3s - loss: 0.4741 - acc: 0.8120 - val_loss: 0.5354 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "7639/7639 - 3s - loss: 0.4817 - acc: 0.8080 - val_loss: 0.5337 - val_acc: 0.8011\n",
      "Epoch 95/100\n",
      "7639/7639 - 3s - loss: 0.4807 - acc: 0.8036 - val_loss: 0.5384 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "7639/7639 - 3s - loss: 0.4832 - acc: 0.8052 - val_loss: 0.5454 - val_acc: 0.7989\n",
      "Epoch 97/100\n",
      "7639/7639 - 3s - loss: 0.4778 - acc: 0.8061 - val_loss: 0.5370 - val_acc: 0.8022\n",
      "Epoch 98/100\n",
      "7639/7639 - 3s - loss: 0.4798 - acc: 0.8069 - val_loss: 0.5417 - val_acc: 0.7989\n",
      "Epoch 99/100\n",
      "7639/7639 - 3s - loss: 0.4744 - acc: 0.8118 - val_loss: 0.5428 - val_acc: 0.7945\n",
      "Epoch 100/100\n",
      "7639/7639 - 3s - loss: 0.4766 - acc: 0.8060 - val_loss: 0.5456 - val_acc: 0.7956\n",
      "Evaluate 0.8021978\n",
      "Fold # 5    Train: (7730, 5, 90)   Test: (819, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7730 samples, validate on 819 samples\n",
      "Epoch 1/100\n",
      "7730/7730 - 5s - loss: 1.4772 - acc: 0.3968 - val_loss: 1.2464 - val_acc: 0.4371\n",
      "Epoch 2/100\n",
      "7730/7730 - 3s - loss: 1.1332 - acc: 0.5801 - val_loss: 1.0490 - val_acc: 0.5336\n",
      "Epoch 3/100\n",
      "7730/7730 - 3s - loss: 0.9510 - acc: 0.6464 - val_loss: 0.9528 - val_acc: 0.5836\n",
      "Epoch 4/100\n",
      "7730/7730 - 3s - loss: 0.8551 - acc: 0.6819 - val_loss: 0.8998 - val_acc: 0.6276\n",
      "Epoch 5/100\n",
      "7730/7730 - 3s - loss: 0.7982 - acc: 0.6917 - val_loss: 0.8698 - val_acc: 0.6361\n",
      "Epoch 6/100\n",
      "7730/7730 - 3s - loss: 0.7552 - acc: 0.7140 - val_loss: 0.8454 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "7730/7730 - 3s - loss: 0.7251 - acc: 0.7194 - val_loss: 0.8358 - val_acc: 0.6447\n",
      "Epoch 8/100\n",
      "7730/7730 - 3s - loss: 0.6958 - acc: 0.7270 - val_loss: 0.8261 - val_acc: 0.6508\n",
      "Epoch 9/100\n",
      "7730/7730 - 3s - loss: 0.6803 - acc: 0.7344 - val_loss: 0.8235 - val_acc: 0.6532\n",
      "Epoch 10/100\n",
      "7730/7730 - 3s - loss: 0.6649 - acc: 0.7436 - val_loss: 0.8189 - val_acc: 0.6630\n",
      "Epoch 11/100\n",
      "7730/7730 - 3s - loss: 0.6523 - acc: 0.7449 - val_loss: 0.8130 - val_acc: 0.6667\n",
      "Epoch 12/100\n",
      "7730/7730 - 3s - loss: 0.6388 - acc: 0.7511 - val_loss: 0.8205 - val_acc: 0.6691\n",
      "Epoch 13/100\n",
      "7730/7730 - 3s - loss: 0.6284 - acc: 0.7542 - val_loss: 0.7930 - val_acc: 0.6764\n",
      "Epoch 14/100\n",
      "7730/7730 - 3s - loss: 0.6225 - acc: 0.7559 - val_loss: 0.7997 - val_acc: 0.6777\n",
      "Epoch 15/100\n",
      "7730/7730 - 3s - loss: 0.6133 - acc: 0.7633 - val_loss: 0.8101 - val_acc: 0.6752\n",
      "Epoch 16/100\n",
      "7730/7730 - 3s - loss: 0.6013 - acc: 0.7656 - val_loss: 0.7934 - val_acc: 0.6813\n",
      "Epoch 17/100\n",
      "7730/7730 - 3s - loss: 0.5946 - acc: 0.7683 - val_loss: 0.7896 - val_acc: 0.6850\n",
      "Epoch 18/100\n",
      "7730/7730 - 3s - loss: 0.5892 - acc: 0.7677 - val_loss: 0.7899 - val_acc: 0.6850\n",
      "Epoch 19/100\n",
      "7730/7730 - 3s - loss: 0.5869 - acc: 0.7695 - val_loss: 0.7743 - val_acc: 0.6899\n",
      "Epoch 20/100\n",
      "7730/7730 - 3s - loss: 0.5848 - acc: 0.7709 - val_loss: 0.7809 - val_acc: 0.6899\n",
      "Epoch 21/100\n",
      "7730/7730 - 3s - loss: 0.5803 - acc: 0.7723 - val_loss: 0.7687 - val_acc: 0.6923\n",
      "Epoch 22/100\n",
      "7730/7730 - 3s - loss: 0.5727 - acc: 0.7766 - val_loss: 0.7657 - val_acc: 0.6911\n",
      "Epoch 23/100\n",
      "7730/7730 - 3s - loss: 0.5765 - acc: 0.7696 - val_loss: 0.7611 - val_acc: 0.6899\n",
      "Epoch 24/100\n",
      "7730/7730 - 3s - loss: 0.5653 - acc: 0.7812 - val_loss: 0.7433 - val_acc: 0.6947\n",
      "Epoch 25/100\n",
      "7730/7730 - 3s - loss: 0.5622 - acc: 0.7805 - val_loss: 0.7568 - val_acc: 0.6911\n",
      "Epoch 26/100\n",
      "7730/7730 - 3s - loss: 0.5571 - acc: 0.7797 - val_loss: 0.7443 - val_acc: 0.6947\n",
      "Epoch 27/100\n",
      "7730/7730 - 3s - loss: 0.5609 - acc: 0.7771 - val_loss: 0.7377 - val_acc: 0.6947\n",
      "Epoch 28/100\n",
      "7730/7730 - 3s - loss: 0.5596 - acc: 0.7765 - val_loss: 0.7375 - val_acc: 0.7009\n",
      "Epoch 29/100\n",
      "7730/7730 - 3s - loss: 0.5498 - acc: 0.7864 - val_loss: 0.7253 - val_acc: 0.7021\n",
      "Epoch 30/100\n",
      "7730/7730 - 3s - loss: 0.5588 - acc: 0.7806 - val_loss: 0.7446 - val_acc: 0.6947\n",
      "Epoch 31/100\n",
      "7730/7730 - 3s - loss: 0.5451 - acc: 0.7859 - val_loss: 0.7174 - val_acc: 0.7033\n",
      "Epoch 32/100\n",
      "7730/7730 - 3s - loss: 0.5481 - acc: 0.7787 - val_loss: 0.7285 - val_acc: 0.7033\n",
      "Epoch 33/100\n",
      "7730/7730 - 3s - loss: 0.5473 - acc: 0.7818 - val_loss: 0.7094 - val_acc: 0.7082\n",
      "Epoch 34/100\n",
      "7730/7730 - 3s - loss: 0.5438 - acc: 0.7806 - val_loss: 0.7092 - val_acc: 0.7094\n",
      "Epoch 35/100\n",
      "7730/7730 - 3s - loss: 0.5394 - acc: 0.7843 - val_loss: 0.7016 - val_acc: 0.7106\n",
      "Epoch 36/100\n",
      "7730/7730 - 3s - loss: 0.5398 - acc: 0.7840 - val_loss: 0.6990 - val_acc: 0.7106\n",
      "Epoch 37/100\n",
      "7730/7730 - 3s - loss: 0.5335 - acc: 0.7902 - val_loss: 0.7083 - val_acc: 0.7057\n",
      "Epoch 38/100\n",
      "7730/7730 - 3s - loss: 0.5347 - acc: 0.7877 - val_loss: 0.6939 - val_acc: 0.7143\n",
      "Epoch 39/100\n",
      "7730/7730 - 3s - loss: 0.5320 - acc: 0.7882 - val_loss: 0.7169 - val_acc: 0.7045\n",
      "Epoch 40/100\n",
      "7730/7730 - 3s - loss: 0.5276 - acc: 0.7921 - val_loss: 0.6939 - val_acc: 0.7094\n",
      "Epoch 41/100\n",
      "7730/7730 - 3s - loss: 0.5306 - acc: 0.7860 - val_loss: 0.7051 - val_acc: 0.7045\n",
      "Epoch 42/100\n",
      "7730/7730 - 3s - loss: 0.5272 - acc: 0.7951 - val_loss: 0.6826 - val_acc: 0.7118\n",
      "Epoch 43/100\n",
      "7730/7730 - 3s - loss: 0.5216 - acc: 0.7931 - val_loss: 0.7256 - val_acc: 0.7009\n",
      "Epoch 44/100\n",
      "7730/7730 - 3s - loss: 0.5202 - acc: 0.7917 - val_loss: 0.6982 - val_acc: 0.7070\n",
      "Epoch 45/100\n",
      "7730/7730 - 3s - loss: 0.5211 - acc: 0.7952 - val_loss: 0.7072 - val_acc: 0.7070\n",
      "Epoch 46/100\n",
      "7730/7730 - 3s - loss: 0.5207 - acc: 0.7942 - val_loss: 0.7040 - val_acc: 0.7070\n",
      "Epoch 47/100\n",
      "7730/7730 - 3s - loss: 0.5181 - acc: 0.7942 - val_loss: 0.6872 - val_acc: 0.7118\n",
      "Epoch 48/100\n",
      "7730/7730 - 3s - loss: 0.5118 - acc: 0.7968 - val_loss: 0.7024 - val_acc: 0.7094\n",
      "Epoch 49/100\n",
      "7730/7730 - 3s - loss: 0.5072 - acc: 0.7974 - val_loss: 0.6828 - val_acc: 0.7118\n",
      "Epoch 50/100\n",
      "7730/7730 - 3s - loss: 0.5090 - acc: 0.8000 - val_loss: 0.6808 - val_acc: 0.7179\n",
      "Epoch 51/100\n",
      "7730/7730 - 3s - loss: 0.5140 - acc: 0.7965 - val_loss: 0.6825 - val_acc: 0.7155\n",
      "Epoch 52/100\n",
      "7730/7730 - 3s - loss: 0.5053 - acc: 0.8027 - val_loss: 0.6736 - val_acc: 0.7204\n",
      "Epoch 53/100\n",
      "7730/7730 - 3s - loss: 0.5050 - acc: 0.8000 - val_loss: 0.6641 - val_acc: 0.7204\n",
      "Epoch 54/100\n",
      "7730/7730 - 3s - loss: 0.5052 - acc: 0.7977 - val_loss: 0.6704 - val_acc: 0.7228\n",
      "Epoch 55/100\n",
      "7730/7730 - 3s - loss: 0.5113 - acc: 0.7982 - val_loss: 0.6795 - val_acc: 0.7155\n",
      "Epoch 56/100\n",
      "7730/7730 - 3s - loss: 0.5059 - acc: 0.8001 - val_loss: 0.6630 - val_acc: 0.7228\n",
      "Epoch 57/100\n",
      "7730/7730 - 3s - loss: 0.5010 - acc: 0.8045 - val_loss: 0.6694 - val_acc: 0.7216\n",
      "Epoch 58/100\n",
      "7730/7730 - 3s - loss: 0.5010 - acc: 0.8035 - val_loss: 0.6704 - val_acc: 0.7204\n",
      "Epoch 59/100\n",
      "7730/7730 - 3s - loss: 0.5047 - acc: 0.8023 - val_loss: 0.6668 - val_acc: 0.7192\n",
      "Epoch 60/100\n",
      "7730/7730 - 3s - loss: 0.4980 - acc: 0.8028 - val_loss: 0.6674 - val_acc: 0.7204\n",
      "Epoch 61/100\n",
      "7730/7730 - 3s - loss: 0.4930 - acc: 0.8080 - val_loss: 0.6697 - val_acc: 0.7192\n",
      "Epoch 62/100\n",
      "7730/7730 - 3s - loss: 0.4978 - acc: 0.8053 - val_loss: 0.6657 - val_acc: 0.7167\n",
      "Epoch 63/100\n",
      "7730/7730 - 3s - loss: 0.4991 - acc: 0.8019 - val_loss: 0.6664 - val_acc: 0.7155\n",
      "Epoch 64/100\n",
      "7730/7730 - 3s - loss: 0.4915 - acc: 0.8050 - val_loss: 0.6487 - val_acc: 0.7192\n",
      "Epoch 65/100\n",
      "7730/7730 - 3s - loss: 0.4997 - acc: 0.8092 - val_loss: 0.6617 - val_acc: 0.7192\n",
      "Epoch 66/100\n",
      "7730/7730 - 3s - loss: 0.4887 - acc: 0.8062 - val_loss: 0.6614 - val_acc: 0.7216\n",
      "Epoch 67/100\n",
      "7730/7730 - 3s - loss: 0.4959 - acc: 0.8031 - val_loss: 0.6540 - val_acc: 0.7192\n",
      "Epoch 68/100\n",
      "7730/7730 - 3s - loss: 0.4908 - acc: 0.8057 - val_loss: 0.6566 - val_acc: 0.7216\n",
      "Epoch 69/100\n",
      "7730/7730 - 3s - loss: 0.4927 - acc: 0.8043 - val_loss: 0.6545 - val_acc: 0.7216\n",
      "Epoch 70/100\n",
      "7730/7730 - 3s - loss: 0.4872 - acc: 0.8053 - val_loss: 0.6433 - val_acc: 0.7241\n",
      "Epoch 71/100\n",
      "7730/7730 - 3s - loss: 0.4886 - acc: 0.8076 - val_loss: 0.6513 - val_acc: 0.7216\n",
      "Epoch 72/100\n",
      "7730/7730 - 3s - loss: 0.4855 - acc: 0.8052 - val_loss: 0.6561 - val_acc: 0.7241\n",
      "Epoch 73/100\n",
      "7730/7730 - 3s - loss: 0.4866 - acc: 0.8039 - val_loss: 0.6587 - val_acc: 0.7179\n",
      "Epoch 74/100\n",
      "7730/7730 - 3s - loss: 0.4867 - acc: 0.8045 - val_loss: 0.6322 - val_acc: 0.7326\n",
      "Epoch 75/100\n",
      "7730/7730 - 3s - loss: 0.4812 - acc: 0.8097 - val_loss: 0.6682 - val_acc: 0.7216\n",
      "Epoch 76/100\n",
      "7730/7730 - 3s - loss: 0.4865 - acc: 0.8092 - val_loss: 0.6468 - val_acc: 0.7253\n",
      "Epoch 77/100\n",
      "7730/7730 - 3s - loss: 0.4793 - acc: 0.8107 - val_loss: 0.6448 - val_acc: 0.7253\n",
      "Epoch 78/100\n",
      "7730/7730 - 3s - loss: 0.4812 - acc: 0.8076 - val_loss: 0.6704 - val_acc: 0.7192\n",
      "Epoch 79/100\n",
      "7730/7730 - 3s - loss: 0.4812 - acc: 0.8115 - val_loss: 0.6577 - val_acc: 0.7228\n",
      "Epoch 80/100\n",
      "7730/7730 - 3s - loss: 0.4739 - acc: 0.8169 - val_loss: 0.6647 - val_acc: 0.7216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "7730/7730 - 3s - loss: 0.4803 - acc: 0.8069 - val_loss: 0.6418 - val_acc: 0.7265\n",
      "Epoch 82/100\n",
      "7730/7730 - 3s - loss: 0.4787 - acc: 0.8116 - val_loss: 0.6658 - val_acc: 0.7192\n",
      "Epoch 83/100\n",
      "7730/7730 - 3s - loss: 0.4726 - acc: 0.8136 - val_loss: 0.6465 - val_acc: 0.7253\n",
      "Epoch 84/100\n",
      "7730/7730 - 3s - loss: 0.4744 - acc: 0.8100 - val_loss: 0.6522 - val_acc: 0.7277\n",
      "Epoch 85/100\n",
      "7730/7730 - 3s - loss: 0.4757 - acc: 0.8151 - val_loss: 0.6693 - val_acc: 0.7253\n",
      "Epoch 86/100\n",
      "7730/7730 - 3s - loss: 0.4699 - acc: 0.8101 - val_loss: 0.6454 - val_acc: 0.7289\n",
      "Epoch 87/100\n",
      "7730/7730 - 3s - loss: 0.4735 - acc: 0.8092 - val_loss: 0.6681 - val_acc: 0.7253\n",
      "Epoch 88/100\n",
      "7730/7730 - 3s - loss: 0.4756 - acc: 0.8140 - val_loss: 0.6525 - val_acc: 0.7253\n",
      "Epoch 89/100\n",
      "7730/7730 - 3s - loss: 0.4686 - acc: 0.8133 - val_loss: 0.6400 - val_acc: 0.7253\n",
      "Epoch 90/100\n",
      "7730/7730 - 3s - loss: 0.4734 - acc: 0.8133 - val_loss: 0.6399 - val_acc: 0.7265\n",
      "Epoch 91/100\n",
      "7730/7730 - 3s - loss: 0.4692 - acc: 0.8146 - val_loss: 0.6445 - val_acc: 0.7277\n",
      "Epoch 92/100\n",
      "7730/7730 - 3s - loss: 0.4697 - acc: 0.8137 - val_loss: 0.6291 - val_acc: 0.7289\n",
      "Epoch 93/100\n",
      "7730/7730 - 3s - loss: 0.4680 - acc: 0.8141 - val_loss: 0.6573 - val_acc: 0.7253\n",
      "Epoch 94/100\n",
      "7730/7730 - 3s - loss: 0.4692 - acc: 0.8105 - val_loss: 0.6420 - val_acc: 0.7253\n",
      "Epoch 95/100\n",
      "7730/7730 - 3s - loss: 0.4676 - acc: 0.8141 - val_loss: 0.6485 - val_acc: 0.7241\n",
      "Epoch 96/100\n",
      "7730/7730 - 3s - loss: 0.4593 - acc: 0.8163 - val_loss: 0.6309 - val_acc: 0.7302\n",
      "Epoch 97/100\n",
      "7730/7730 - 3s - loss: 0.4749 - acc: 0.8088 - val_loss: 0.6392 - val_acc: 0.7277\n",
      "Epoch 98/100\n",
      "7730/7730 - 3s - loss: 0.4668 - acc: 0.8181 - val_loss: 0.6457 - val_acc: 0.7241\n",
      "Epoch 99/100\n",
      "7730/7730 - 3s - loss: 0.4723 - acc: 0.8100 - val_loss: 0.6401 - val_acc: 0.7253\n",
      "Epoch 100/100\n",
      "7730/7730 - 3s - loss: 0.4638 - acc: 0.8136 - val_loss: 0.6395 - val_acc: 0.7265\n",
      "Evaluate 0.73260075\n",
      "Fold # 6    Train: (7769, 5, 90)   Test: (780, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7769 samples, validate on 780 samples\n",
      "Epoch 1/100\n",
      "7769/7769 - 6s - loss: 1.4996 - acc: 0.3583 - val_loss: 1.1120 - val_acc: 0.5679\n",
      "Epoch 2/100\n",
      "7769/7769 - 3s - loss: 1.1299 - acc: 0.5707 - val_loss: 0.9703 - val_acc: 0.5692\n",
      "Epoch 3/100\n",
      "7769/7769 - 3s - loss: 0.9487 - acc: 0.6450 - val_loss: 1.0089 - val_acc: 0.5731\n",
      "Epoch 4/100\n",
      "7769/7769 - 3s - loss: 0.8557 - acc: 0.6799 - val_loss: 1.0479 - val_acc: 0.5744\n",
      "Epoch 5/100\n",
      "7769/7769 - 3s - loss: 0.8014 - acc: 0.6949 - val_loss: 1.0802 - val_acc: 0.5756\n",
      "Epoch 6/100\n",
      "7769/7769 - 3s - loss: 0.7601 - acc: 0.7096 - val_loss: 1.0995 - val_acc: 0.5795\n",
      "Epoch 7/100\n",
      "7769/7769 - 3s - loss: 0.7305 - acc: 0.7240 - val_loss: 1.1120 - val_acc: 0.5833\n",
      "Epoch 8/100\n",
      "7769/7769 - 3s - loss: 0.7078 - acc: 0.7249 - val_loss: 1.1237 - val_acc: 0.5846\n",
      "Epoch 9/100\n",
      "7769/7769 - 3s - loss: 0.6790 - acc: 0.7396 - val_loss: 1.1174 - val_acc: 0.5885\n",
      "Epoch 10/100\n",
      "7769/7769 - 3s - loss: 0.6683 - acc: 0.7405 - val_loss: 1.1173 - val_acc: 0.5910\n",
      "Epoch 11/100\n",
      "7769/7769 - 3s - loss: 0.6512 - acc: 0.7459 - val_loss: 1.1157 - val_acc: 0.5962\n",
      "Epoch 12/100\n",
      "7769/7769 - 3s - loss: 0.6363 - acc: 0.7562 - val_loss: 1.1270 - val_acc: 0.5987\n",
      "Epoch 13/100\n",
      "7769/7769 - 3s - loss: 0.6297 - acc: 0.7560 - val_loss: 1.0950 - val_acc: 0.6051\n",
      "Epoch 14/100\n",
      "7769/7769 - 3s - loss: 0.6202 - acc: 0.7567 - val_loss: 1.1053 - val_acc: 0.6128\n",
      "Epoch 15/100\n",
      "7769/7769 - 3s - loss: 0.6070 - acc: 0.7623 - val_loss: 1.0883 - val_acc: 0.6141\n",
      "Epoch 16/100\n",
      "7769/7769 - 3s - loss: 0.5967 - acc: 0.7665 - val_loss: 1.0766 - val_acc: 0.6218\n",
      "Epoch 17/100\n",
      "7769/7769 - 3s - loss: 0.6010 - acc: 0.7633 - val_loss: 1.0838 - val_acc: 0.6269\n",
      "Epoch 18/100\n",
      "7769/7769 - 3s - loss: 0.5869 - acc: 0.7711 - val_loss: 1.0687 - val_acc: 0.6385\n",
      "Epoch 19/100\n",
      "7769/7769 - 3s - loss: 0.5845 - acc: 0.7700 - val_loss: 1.0627 - val_acc: 0.6397\n",
      "Epoch 20/100\n",
      "7769/7769 - 3s - loss: 0.5814 - acc: 0.7701 - val_loss: 1.0514 - val_acc: 0.6462\n",
      "Epoch 21/100\n",
      "7769/7769 - 3s - loss: 0.5771 - acc: 0.7759 - val_loss: 1.0506 - val_acc: 0.6487\n",
      "Epoch 22/100\n",
      "7769/7769 - 3s - loss: 0.5739 - acc: 0.7741 - val_loss: 1.0229 - val_acc: 0.6615\n",
      "Epoch 23/100\n",
      "7769/7769 - 3s - loss: 0.5653 - acc: 0.7732 - val_loss: 1.0155 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "7769/7769 - 3s - loss: 0.5658 - acc: 0.7774 - val_loss: 1.0125 - val_acc: 0.6705\n",
      "Epoch 25/100\n",
      "7769/7769 - 3s - loss: 0.5625 - acc: 0.7753 - val_loss: 1.0149 - val_acc: 0.6692\n",
      "Epoch 26/100\n",
      "7769/7769 - 3s - loss: 0.5560 - acc: 0.7772 - val_loss: 0.9827 - val_acc: 0.6718\n",
      "Epoch 27/100\n",
      "7769/7769 - 3s - loss: 0.5564 - acc: 0.7785 - val_loss: 0.9847 - val_acc: 0.6744\n",
      "Epoch 28/100\n",
      "7769/7769 - 3s - loss: 0.5491 - acc: 0.7822 - val_loss: 0.9694 - val_acc: 0.6756\n",
      "Epoch 29/100\n",
      "7769/7769 - 3s - loss: 0.5477 - acc: 0.7821 - val_loss: 0.9689 - val_acc: 0.6744\n",
      "Epoch 30/100\n",
      "7769/7769 - 3s - loss: 0.5450 - acc: 0.7830 - val_loss: 0.9606 - val_acc: 0.6769\n",
      "Epoch 31/100\n",
      "7769/7769 - 3s - loss: 0.5378 - acc: 0.7821 - val_loss: 0.9513 - val_acc: 0.6795\n",
      "Epoch 32/100\n",
      "7769/7769 - 3s - loss: 0.5346 - acc: 0.7854 - val_loss: 0.9615 - val_acc: 0.6795\n",
      "Epoch 33/100\n",
      "7769/7769 - 3s - loss: 0.5407 - acc: 0.7836 - val_loss: 0.9525 - val_acc: 0.6808\n",
      "Epoch 34/100\n",
      "7769/7769 - 3s - loss: 0.5428 - acc: 0.7852 - val_loss: 0.9390 - val_acc: 0.6821\n",
      "Epoch 35/100\n",
      "7769/7769 - 3s - loss: 0.5404 - acc: 0.7867 - val_loss: 0.9561 - val_acc: 0.6859\n",
      "Epoch 36/100\n",
      "7769/7769 - 3s - loss: 0.5406 - acc: 0.7793 - val_loss: 0.9271 - val_acc: 0.6897\n",
      "Epoch 37/100\n",
      "7769/7769 - 3s - loss: 0.5327 - acc: 0.7910 - val_loss: 0.9079 - val_acc: 0.6923\n",
      "Epoch 38/100\n",
      "7769/7769 - 3s - loss: 0.5299 - acc: 0.7883 - val_loss: 0.9221 - val_acc: 0.6936\n",
      "Epoch 39/100\n",
      "7769/7769 - 3s - loss: 0.5292 - acc: 0.7863 - val_loss: 0.9253 - val_acc: 0.6910\n",
      "Epoch 40/100\n",
      "7769/7769 - 3s - loss: 0.5294 - acc: 0.7879 - val_loss: 0.9110 - val_acc: 0.6962\n",
      "Epoch 41/100\n",
      "7769/7769 - 3s - loss: 0.5280 - acc: 0.7907 - val_loss: 0.8869 - val_acc: 0.7013\n",
      "Epoch 42/100\n",
      "7769/7769 - 3s - loss: 0.5245 - acc: 0.7906 - val_loss: 0.9033 - val_acc: 0.7013\n",
      "Epoch 43/100\n",
      "7769/7769 - 3s - loss: 0.5183 - acc: 0.7943 - val_loss: 0.9026 - val_acc: 0.7026\n",
      "Epoch 44/100\n",
      "7769/7769 - 3s - loss: 0.5176 - acc: 0.7920 - val_loss: 0.8970 - val_acc: 0.7038\n",
      "Epoch 45/100\n",
      "7769/7769 - 3s - loss: 0.5200 - acc: 0.7924 - val_loss: 0.8755 - val_acc: 0.7103\n",
      "Epoch 46/100\n",
      "7769/7769 - 3s - loss: 0.5209 - acc: 0.7932 - val_loss: 0.8965 - val_acc: 0.7090\n",
      "Epoch 47/100\n",
      "7769/7769 - 3s - loss: 0.5154 - acc: 0.7966 - val_loss: 0.8903 - val_acc: 0.7115\n",
      "Epoch 48/100\n",
      "7769/7769 - 3s - loss: 0.5153 - acc: 0.7951 - val_loss: 0.8737 - val_acc: 0.7103\n",
      "Epoch 49/100\n",
      "7769/7769 - 3s - loss: 0.5153 - acc: 0.7979 - val_loss: 0.8975 - val_acc: 0.7090\n",
      "Epoch 50/100\n",
      "7769/7769 - 3s - loss: 0.5170 - acc: 0.7955 - val_loss: 0.8825 - val_acc: 0.7205\n",
      "Epoch 51/100\n",
      "7769/7769 - 3s - loss: 0.5103 - acc: 0.8016 - val_loss: 0.8872 - val_acc: 0.7179\n",
      "Epoch 52/100\n",
      "7769/7769 - 3s - loss: 0.5058 - acc: 0.7950 - val_loss: 0.8658 - val_acc: 0.7218\n",
      "Epoch 53/100\n",
      "7769/7769 - 3s - loss: 0.5011 - acc: 0.8029 - val_loss: 0.8740 - val_acc: 0.7218\n",
      "Epoch 54/100\n",
      "7769/7769 - 3s - loss: 0.5093 - acc: 0.7947 - val_loss: 0.8570 - val_acc: 0.7244\n",
      "Epoch 55/100\n",
      "7769/7769 - 3s - loss: 0.5065 - acc: 0.7998 - val_loss: 0.8765 - val_acc: 0.7218\n",
      "Epoch 56/100\n",
      "7769/7769 - 3s - loss: 0.5020 - acc: 0.7965 - val_loss: 0.8598 - val_acc: 0.7282\n",
      "Epoch 57/100\n",
      "7769/7769 - 3s - loss: 0.5013 - acc: 0.8014 - val_loss: 0.8530 - val_acc: 0.7282\n",
      "Epoch 58/100\n",
      "7769/7769 - 3s - loss: 0.5028 - acc: 0.7973 - val_loss: 0.8497 - val_acc: 0.7256\n",
      "Epoch 59/100\n",
      "7769/7769 - 3s - loss: 0.5024 - acc: 0.7966 - val_loss: 0.8743 - val_acc: 0.7256\n",
      "Epoch 60/100\n",
      "7769/7769 - 3s - loss: 0.4962 - acc: 0.8005 - val_loss: 0.8474 - val_acc: 0.7295\n",
      "Epoch 61/100\n",
      "7769/7769 - 3s - loss: 0.5032 - acc: 0.7983 - val_loss: 0.8688 - val_acc: 0.7269\n",
      "Epoch 62/100\n",
      "7769/7769 - 3s - loss: 0.4975 - acc: 0.7992 - val_loss: 0.8488 - val_acc: 0.7282\n",
      "Epoch 63/100\n",
      "7769/7769 - 3s - loss: 0.4955 - acc: 0.8037 - val_loss: 0.8597 - val_acc: 0.7295\n",
      "Epoch 64/100\n",
      "7769/7769 - 3s - loss: 0.4976 - acc: 0.7966 - val_loss: 0.8590 - val_acc: 0.7333\n",
      "Epoch 65/100\n",
      "7769/7769 - 3s - loss: 0.4920 - acc: 0.8015 - val_loss: 0.8508 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "7769/7769 - 3s - loss: 0.4870 - acc: 0.8044 - val_loss: 0.8377 - val_acc: 0.7333\n",
      "Epoch 67/100\n",
      "7769/7769 - 3s - loss: 0.4899 - acc: 0.8059 - val_loss: 0.8476 - val_acc: 0.7333\n",
      "Epoch 68/100\n",
      "7769/7769 - 3s - loss: 0.4877 - acc: 0.8059 - val_loss: 0.8445 - val_acc: 0.7321\n",
      "Epoch 69/100\n",
      "7769/7769 - 3s - loss: 0.4916 - acc: 0.8069 - val_loss: 0.8435 - val_acc: 0.7333\n",
      "Epoch 70/100\n",
      "7769/7769 - 3s - loss: 0.4934 - acc: 0.8032 - val_loss: 0.8423 - val_acc: 0.7333\n",
      "Epoch 71/100\n",
      "7769/7769 - 3s - loss: 0.4822 - acc: 0.8098 - val_loss: 0.8448 - val_acc: 0.7333\n",
      "Epoch 72/100\n",
      "7769/7769 - 3s - loss: 0.4893 - acc: 0.8046 - val_loss: 0.8411 - val_acc: 0.7333\n",
      "Epoch 73/100\n",
      "7769/7769 - 3s - loss: 0.4929 - acc: 0.8059 - val_loss: 0.8394 - val_acc: 0.7333\n",
      "Epoch 74/100\n",
      "7769/7769 - 3s - loss: 0.4813 - acc: 0.8125 - val_loss: 0.8368 - val_acc: 0.7333\n",
      "Epoch 75/100\n",
      "7769/7769 - 3s - loss: 0.4856 - acc: 0.8018 - val_loss: 0.8379 - val_acc: 0.7333\n",
      "Epoch 76/100\n",
      "7769/7769 - 3s - loss: 0.4868 - acc: 0.8041 - val_loss: 0.8195 - val_acc: 0.7333\n",
      "Epoch 77/100\n",
      "7769/7769 - 3s - loss: 0.4834 - acc: 0.8069 - val_loss: 0.8398 - val_acc: 0.7333\n",
      "Epoch 78/100\n",
      "7769/7769 - 3s - loss: 0.4834 - acc: 0.8090 - val_loss: 0.8281 - val_acc: 0.7346\n",
      "Epoch 79/100\n",
      "7769/7769 - 3s - loss: 0.4814 - acc: 0.8063 - val_loss: 0.8234 - val_acc: 0.7359\n",
      "Epoch 80/100\n",
      "7769/7769 - 3s - loss: 0.4825 - acc: 0.8096 - val_loss: 0.8201 - val_acc: 0.7346\n",
      "Epoch 81/100\n",
      "7769/7769 - 3s - loss: 0.4794 - acc: 0.8137 - val_loss: 0.8077 - val_acc: 0.7372\n",
      "Epoch 82/100\n",
      "7769/7769 - 3s - loss: 0.4807 - acc: 0.8078 - val_loss: 0.8135 - val_acc: 0.7346\n",
      "Epoch 83/100\n",
      "7769/7769 - 3s - loss: 0.4787 - acc: 0.8099 - val_loss: 0.8138 - val_acc: 0.7346\n",
      "Epoch 84/100\n",
      "7769/7769 - 3s - loss: 0.4731 - acc: 0.8101 - val_loss: 0.8190 - val_acc: 0.7359\n",
      "Epoch 85/100\n",
      "7769/7769 - 3s - loss: 0.4758 - acc: 0.8076 - val_loss: 0.8168 - val_acc: 0.7359\n",
      "Epoch 86/100\n",
      "7769/7769 - 3s - loss: 0.4812 - acc: 0.8127 - val_loss: 0.8308 - val_acc: 0.7359\n",
      "Epoch 87/100\n",
      "7769/7769 - 3s - loss: 0.4748 - acc: 0.8094 - val_loss: 0.8084 - val_acc: 0.7359\n",
      "Epoch 88/100\n",
      "7769/7769 - 3s - loss: 0.4735 - acc: 0.8104 - val_loss: 0.8193 - val_acc: 0.7359\n",
      "Epoch 89/100\n",
      "7769/7769 - 3s - loss: 0.4727 - acc: 0.8109 - val_loss: 0.8150 - val_acc: 0.7359\n",
      "Epoch 90/100\n",
      "7769/7769 - 3s - loss: 0.4782 - acc: 0.8055 - val_loss: 0.8106 - val_acc: 0.7372\n",
      "Epoch 91/100\n",
      "7769/7769 - 3s - loss: 0.4711 - acc: 0.8125 - val_loss: 0.8075 - val_acc: 0.7372\n",
      "Epoch 92/100\n",
      "7769/7769 - 3s - loss: 0.4700 - acc: 0.8122 - val_loss: 0.8065 - val_acc: 0.7372\n",
      "Epoch 93/100\n",
      "7769/7769 - 3s - loss: 0.4734 - acc: 0.8098 - val_loss: 0.8049 - val_acc: 0.7359\n",
      "Epoch 94/100\n",
      "7769/7769 - 3s - loss: 0.4675 - acc: 0.8137 - val_loss: 0.8080 - val_acc: 0.7385\n",
      "Epoch 95/100\n",
      "7769/7769 - 3s - loss: 0.4715 - acc: 0.8128 - val_loss: 0.7927 - val_acc: 0.7397\n",
      "Epoch 96/100\n",
      "7769/7769 - 3s - loss: 0.4653 - acc: 0.8163 - val_loss: 0.8047 - val_acc: 0.7397\n",
      "Epoch 97/100\n",
      "7769/7769 - 3s - loss: 0.4685 - acc: 0.8110 - val_loss: 0.7946 - val_acc: 0.7385\n",
      "Epoch 98/100\n",
      "7769/7769 - 3s - loss: 0.4651 - acc: 0.8146 - val_loss: 0.8095 - val_acc: 0.7385\n",
      "Epoch 99/100\n",
      "7769/7769 - 3s - loss: 0.4694 - acc: 0.8109 - val_loss: 0.7970 - val_acc: 0.7397\n",
      "Epoch 100/100\n",
      "7769/7769 - 3s - loss: 0.4677 - acc: 0.8118 - val_loss: 0.8106 - val_acc: 0.7385\n",
      "Evaluate 0.7397436\n",
      "Fold # 7    Train: (7583, 5, 90)   Test: (966, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7583 samples, validate on 966 samples\n",
      "Epoch 1/100\n",
      "7583/7583 - 6s - loss: 1.4880 - acc: 0.3587 - val_loss: 1.2559 - val_acc: 0.5062\n",
      "Epoch 2/100\n",
      "7583/7583 - 3s - loss: 1.1536 - acc: 0.5613 - val_loss: 0.9278 - val_acc: 0.5994\n",
      "Epoch 3/100\n",
      "7583/7583 - 3s - loss: 0.9854 - acc: 0.6242 - val_loss: 0.7938 - val_acc: 0.7008\n",
      "Epoch 4/100\n",
      "7583/7583 - 3s - loss: 0.8903 - acc: 0.6687 - val_loss: 0.7296 - val_acc: 0.7246\n",
      "Epoch 5/100\n",
      "7583/7583 - 3s - loss: 0.8381 - acc: 0.6828 - val_loss: 0.6727 - val_acc: 0.7391\n",
      "Epoch 6/100\n",
      "7583/7583 - 3s - loss: 0.7987 - acc: 0.6885 - val_loss: 0.6297 - val_acc: 0.7495\n",
      "Epoch 7/100\n",
      "7583/7583 - 3s - loss: 0.7660 - acc: 0.7024 - val_loss: 0.5969 - val_acc: 0.7598\n",
      "Epoch 8/100\n",
      "7583/7583 - 3s - loss: 0.7425 - acc: 0.7136 - val_loss: 0.5670 - val_acc: 0.7712\n",
      "Epoch 9/100\n",
      "7583/7583 - 3s - loss: 0.7176 - acc: 0.7231 - val_loss: 0.5364 - val_acc: 0.7816\n",
      "Epoch 10/100\n",
      "7583/7583 - 3s - loss: 0.6984 - acc: 0.7341 - val_loss: 0.5270 - val_acc: 0.7867\n",
      "Epoch 11/100\n",
      "7583/7583 - 3s - loss: 0.6870 - acc: 0.7306 - val_loss: 0.5070 - val_acc: 0.7950\n",
      "Epoch 12/100\n",
      "7583/7583 - 4s - loss: 0.6689 - acc: 0.7392 - val_loss: 0.4947 - val_acc: 0.7992\n",
      "Epoch 13/100\n",
      "7583/7583 - 3s - loss: 0.6679 - acc: 0.7376 - val_loss: 0.4854 - val_acc: 0.8002\n",
      "Epoch 14/100\n",
      "7583/7583 - 3s - loss: 0.6524 - acc: 0.7448 - val_loss: 0.4730 - val_acc: 0.7992\n",
      "Epoch 15/100\n",
      "7583/7583 - 3s - loss: 0.6463 - acc: 0.7443 - val_loss: 0.4690 - val_acc: 0.8043\n",
      "Epoch 16/100\n",
      "7583/7583 - 3s - loss: 0.6326 - acc: 0.7530 - val_loss: 0.4458 - val_acc: 0.8137\n",
      "Epoch 17/100\n",
      "7583/7583 - 3s - loss: 0.6335 - acc: 0.7508 - val_loss: 0.4421 - val_acc: 0.8126\n",
      "Epoch 18/100\n",
      "7583/7583 - 3s - loss: 0.6202 - acc: 0.7554 - val_loss: 0.4370 - val_acc: 0.8157\n",
      "Epoch 19/100\n",
      "7583/7583 - 3s - loss: 0.6184 - acc: 0.7545 - val_loss: 0.4312 - val_acc: 0.8209\n",
      "Epoch 20/100\n",
      "7583/7583 - 3s - loss: 0.6131 - acc: 0.7580 - val_loss: 0.4277 - val_acc: 0.8219\n",
      "Epoch 21/100\n",
      "7583/7583 - 4s - loss: 0.6115 - acc: 0.7579 - val_loss: 0.4163 - val_acc: 0.8313\n",
      "Epoch 22/100\n",
      "7583/7583 - 3s - loss: 0.6051 - acc: 0.7591 - val_loss: 0.4208 - val_acc: 0.8251\n",
      "Epoch 23/100\n",
      "7583/7583 - 3s - loss: 0.6017 - acc: 0.7628 - val_loss: 0.4103 - val_acc: 0.8302\n",
      "Epoch 24/100\n",
      "7583/7583 - 3s - loss: 0.6012 - acc: 0.7650 - val_loss: 0.4115 - val_acc: 0.8292\n",
      "Epoch 25/100\n",
      "7583/7583 - 3s - loss: 0.5986 - acc: 0.7638 - val_loss: 0.4010 - val_acc: 0.8375\n",
      "Epoch 26/100\n",
      "7583/7583 - 3s - loss: 0.5901 - acc: 0.7617 - val_loss: 0.4054 - val_acc: 0.8344\n",
      "Epoch 27/100\n",
      "7583/7583 - 3s - loss: 0.5856 - acc: 0.7692 - val_loss: 0.3991 - val_acc: 0.8354\n",
      "Epoch 28/100\n",
      "7583/7583 - 3s - loss: 0.5797 - acc: 0.7684 - val_loss: 0.4018 - val_acc: 0.8354\n",
      "Epoch 29/100\n",
      "7583/7583 - 3s - loss: 0.5843 - acc: 0.7691 - val_loss: 0.3992 - val_acc: 0.8333\n",
      "Epoch 30/100\n",
      "7583/7583 - 3s - loss: 0.5767 - acc: 0.7709 - val_loss: 0.3984 - val_acc: 0.8333\n",
      "Epoch 31/100\n",
      "7583/7583 - 3s - loss: 0.5711 - acc: 0.7738 - val_loss: 0.3923 - val_acc: 0.8354\n",
      "Epoch 32/100\n",
      "7583/7583 - 3s - loss: 0.5742 - acc: 0.7712 - val_loss: 0.3864 - val_acc: 0.8375\n",
      "Epoch 33/100\n",
      "7583/7583 - 3s - loss: 0.5685 - acc: 0.7759 - val_loss: 0.3863 - val_acc: 0.8375\n",
      "Epoch 34/100\n",
      "7583/7583 - 3s - loss: 0.5677 - acc: 0.7763 - val_loss: 0.3810 - val_acc: 0.8447\n",
      "Epoch 35/100\n",
      "7583/7583 - 3s - loss: 0.5613 - acc: 0.7787 - val_loss: 0.3878 - val_acc: 0.8385\n",
      "Epoch 36/100\n",
      "7583/7583 - 3s - loss: 0.5671 - acc: 0.7723 - val_loss: 0.3929 - val_acc: 0.8354\n",
      "Epoch 37/100\n",
      "7583/7583 - 3s - loss: 0.5677 - acc: 0.7833 - val_loss: 0.3873 - val_acc: 0.8385\n",
      "Epoch 38/100\n",
      "7583/7583 - 3s - loss: 0.5583 - acc: 0.7766 - val_loss: 0.3872 - val_acc: 0.8375\n",
      "Epoch 39/100\n",
      "7583/7583 - 4s - loss: 0.5607 - acc: 0.7777 - val_loss: 0.3847 - val_acc: 0.8375\n",
      "Epoch 40/100\n",
      "7583/7583 - 4s - loss: 0.5588 - acc: 0.7769 - val_loss: 0.3824 - val_acc: 0.8395\n",
      "Epoch 41/100\n",
      "7583/7583 - 3s - loss: 0.5497 - acc: 0.7849 - val_loss: 0.3879 - val_acc: 0.8385\n",
      "Epoch 42/100\n",
      "7583/7583 - 3s - loss: 0.5532 - acc: 0.7782 - val_loss: 0.3815 - val_acc: 0.8427\n",
      "Epoch 43/100\n",
      "7583/7583 - 4s - loss: 0.5525 - acc: 0.7750 - val_loss: 0.3781 - val_acc: 0.8395\n",
      "Epoch 44/100\n",
      "7583/7583 - 4s - loss: 0.5483 - acc: 0.7788 - val_loss: 0.3771 - val_acc: 0.8427\n",
      "Epoch 45/100\n",
      "7583/7583 - 3s - loss: 0.5457 - acc: 0.7852 - val_loss: 0.3760 - val_acc: 0.8437\n",
      "Epoch 46/100\n",
      "7583/7583 - 3s - loss: 0.5421 - acc: 0.7878 - val_loss: 0.3760 - val_acc: 0.8416\n",
      "Epoch 47/100\n",
      "7583/7583 - 3s - loss: 0.5425 - acc: 0.7812 - val_loss: 0.3771 - val_acc: 0.8427\n",
      "Epoch 48/100\n",
      "7583/7583 - 3s - loss: 0.5449 - acc: 0.7791 - val_loss: 0.3693 - val_acc: 0.8447\n",
      "Epoch 49/100\n",
      "7583/7583 - 4s - loss: 0.5394 - acc: 0.7841 - val_loss: 0.3628 - val_acc: 0.8551\n",
      "Epoch 50/100\n",
      "7583/7583 - 3s - loss: 0.5416 - acc: 0.7811 - val_loss: 0.3697 - val_acc: 0.8478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "7583/7583 - 3s - loss: 0.5384 - acc: 0.7821 - val_loss: 0.3655 - val_acc: 0.8468\n",
      "Epoch 52/100\n",
      "7583/7583 - 3s - loss: 0.5392 - acc: 0.7835 - val_loss: 0.3718 - val_acc: 0.8437\n",
      "Epoch 53/100\n",
      "7583/7583 - 3s - loss: 0.5379 - acc: 0.7825 - val_loss: 0.3632 - val_acc: 0.8499\n",
      "Epoch 54/100\n",
      "7583/7583 - 3s - loss: 0.5295 - acc: 0.7891 - val_loss: 0.3644 - val_acc: 0.8499\n",
      "Epoch 55/100\n",
      "7583/7583 - 4s - loss: 0.5324 - acc: 0.7854 - val_loss: 0.3648 - val_acc: 0.8499\n",
      "Epoch 56/100\n",
      "7583/7583 - 4s - loss: 0.5364 - acc: 0.7843 - val_loss: 0.3768 - val_acc: 0.8447\n",
      "Epoch 57/100\n",
      "7583/7583 - 3s - loss: 0.5367 - acc: 0.7866 - val_loss: 0.3799 - val_acc: 0.8437\n",
      "Epoch 58/100\n",
      "7583/7583 - 3s - loss: 0.5304 - acc: 0.7872 - val_loss: 0.3682 - val_acc: 0.8509\n",
      "Epoch 59/100\n",
      "7583/7583 - 3s - loss: 0.5284 - acc: 0.7873 - val_loss: 0.3723 - val_acc: 0.8478\n",
      "Epoch 60/100\n",
      "7583/7583 - 3s - loss: 0.5282 - acc: 0.7872 - val_loss: 0.3705 - val_acc: 0.8509\n",
      "Epoch 61/100\n",
      "7583/7583 - 3s - loss: 0.5272 - acc: 0.7883 - val_loss: 0.3685 - val_acc: 0.8499\n",
      "Epoch 62/100\n",
      "7583/7583 - 3s - loss: 0.5261 - acc: 0.7922 - val_loss: 0.3680 - val_acc: 0.8489\n",
      "Epoch 63/100\n",
      "7583/7583 - 3s - loss: 0.5199 - acc: 0.7894 - val_loss: 0.3727 - val_acc: 0.8489\n",
      "Epoch 64/100\n",
      "7583/7583 - 3s - loss: 0.5204 - acc: 0.7889 - val_loss: 0.3660 - val_acc: 0.8509\n",
      "Epoch 65/100\n",
      "7583/7583 - 3s - loss: 0.5216 - acc: 0.7918 - val_loss: 0.3660 - val_acc: 0.8489\n",
      "Epoch 66/100\n",
      "7583/7583 - 3s - loss: 0.5137 - acc: 0.7961 - val_loss: 0.3746 - val_acc: 0.8458\n",
      "Epoch 67/100\n",
      "7583/7583 - 3s - loss: 0.5181 - acc: 0.7949 - val_loss: 0.3732 - val_acc: 0.8478\n",
      "Epoch 68/100\n",
      "7583/7583 - 3s - loss: 0.5185 - acc: 0.7948 - val_loss: 0.3621 - val_acc: 0.8530\n",
      "Epoch 69/100\n",
      "7583/7583 - 3s - loss: 0.5186 - acc: 0.7868 - val_loss: 0.3707 - val_acc: 0.8478\n",
      "Epoch 70/100\n",
      "7583/7583 - 3s - loss: 0.5099 - acc: 0.8013 - val_loss: 0.3653 - val_acc: 0.8489\n",
      "Epoch 71/100\n",
      "7583/7583 - 3s - loss: 0.5178 - acc: 0.7948 - val_loss: 0.3590 - val_acc: 0.8540\n",
      "Epoch 72/100\n",
      "7583/7583 - 3s - loss: 0.5173 - acc: 0.7951 - val_loss: 0.3621 - val_acc: 0.8530\n",
      "Epoch 73/100\n",
      "7583/7583 - 4s - loss: 0.5106 - acc: 0.7941 - val_loss: 0.3574 - val_acc: 0.8571\n",
      "Epoch 74/100\n",
      "7583/7583 - 3s - loss: 0.5148 - acc: 0.7924 - val_loss: 0.3653 - val_acc: 0.8520\n",
      "Epoch 75/100\n",
      "7583/7583 - 3s - loss: 0.5115 - acc: 0.7951 - val_loss: 0.3687 - val_acc: 0.8499\n",
      "Epoch 76/100\n",
      "7583/7583 - 3s - loss: 0.5089 - acc: 0.7961 - val_loss: 0.3710 - val_acc: 0.8489\n",
      "Epoch 77/100\n",
      "7583/7583 - 4s - loss: 0.5031 - acc: 0.8030 - val_loss: 0.3647 - val_acc: 0.8520\n",
      "Epoch 78/100\n",
      "7583/7583 - 3s - loss: 0.5077 - acc: 0.7969 - val_loss: 0.3593 - val_acc: 0.8551\n",
      "Epoch 79/100\n",
      "7583/7583 - 3s - loss: 0.5057 - acc: 0.7957 - val_loss: 0.3594 - val_acc: 0.8540\n",
      "Epoch 80/100\n",
      "7583/7583 - 3s - loss: 0.5007 - acc: 0.7986 - val_loss: 0.3594 - val_acc: 0.8551\n",
      "Epoch 81/100\n",
      "7583/7583 - 3s - loss: 0.5042 - acc: 0.7965 - val_loss: 0.3608 - val_acc: 0.8520\n",
      "Epoch 82/100\n",
      "7583/7583 - 3s - loss: 0.5022 - acc: 0.7999 - val_loss: 0.3558 - val_acc: 0.8540\n",
      "Epoch 83/100\n",
      "7583/7583 - 4s - loss: 0.5035 - acc: 0.7970 - val_loss: 0.3549 - val_acc: 0.8592\n",
      "Epoch 84/100\n",
      "7583/7583 - 3s - loss: 0.5052 - acc: 0.7993 - val_loss: 0.3646 - val_acc: 0.8489\n",
      "Epoch 85/100\n",
      "7583/7583 - 3s - loss: 0.5013 - acc: 0.7972 - val_loss: 0.3591 - val_acc: 0.8551\n",
      "Epoch 86/100\n",
      "7583/7583 - 4s - loss: 0.4989 - acc: 0.8015 - val_loss: 0.3602 - val_acc: 0.8509\n",
      "Epoch 87/100\n",
      "7583/7583 - 3s - loss: 0.5055 - acc: 0.7952 - val_loss: 0.3615 - val_acc: 0.8551\n",
      "Epoch 88/100\n",
      "7583/7583 - 3s - loss: 0.4978 - acc: 0.7986 - val_loss: 0.3656 - val_acc: 0.8489\n",
      "Epoch 89/100\n",
      "7583/7583 - 3s - loss: 0.4996 - acc: 0.8002 - val_loss: 0.3629 - val_acc: 0.8520\n",
      "Epoch 90/100\n",
      "7583/7583 - 3s - loss: 0.4919 - acc: 0.8031 - val_loss: 0.3592 - val_acc: 0.8551\n",
      "Epoch 91/100\n",
      "7583/7583 - 3s - loss: 0.4946 - acc: 0.8048 - val_loss: 0.3615 - val_acc: 0.8520\n",
      "Epoch 92/100\n",
      "7583/7583 - 3s - loss: 0.4893 - acc: 0.8036 - val_loss: 0.3605 - val_acc: 0.8478\n",
      "Epoch 93/100\n",
      "7583/7583 - 3s - loss: 0.4967 - acc: 0.8010 - val_loss: 0.3578 - val_acc: 0.8530\n",
      "Epoch 94/100\n",
      "7583/7583 - 4s - loss: 0.4962 - acc: 0.8003 - val_loss: 0.3627 - val_acc: 0.8468\n",
      "Epoch 95/100\n",
      "7583/7583 - 3s - loss: 0.4970 - acc: 0.7988 - val_loss: 0.3600 - val_acc: 0.8530\n",
      "Epoch 96/100\n",
      "7583/7583 - 3s - loss: 0.4935 - acc: 0.8021 - val_loss: 0.3647 - val_acc: 0.8468\n",
      "Epoch 97/100\n",
      "7583/7583 - 3s - loss: 0.4837 - acc: 0.8096 - val_loss: 0.3595 - val_acc: 0.8520\n",
      "Epoch 98/100\n",
      "7583/7583 - 3s - loss: 0.4934 - acc: 0.8035 - val_loss: 0.3596 - val_acc: 0.8530\n",
      "Epoch 99/100\n",
      "7583/7583 - 3s - loss: 0.4941 - acc: 0.8040 - val_loss: 0.3650 - val_acc: 0.8468\n",
      "Epoch 100/100\n",
      "7583/7583 - 3s - loss: 0.4927 - acc: 0.8023 - val_loss: 0.3590 - val_acc: 0.8530\n",
      "Evaluate 0.85921323\n",
      "Fold # 8    Train: (7614, 5, 90)   Test: (935, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7614 samples, validate on 935 samples\n",
      "Epoch 1/100\n",
      "7614/7614 - 7s - loss: 1.4520 - acc: 0.4142 - val_loss: 1.2856 - val_acc: 0.4299\n",
      "Epoch 2/100\n",
      "7614/7614 - 3s - loss: 1.1186 - acc: 0.5975 - val_loss: 1.1485 - val_acc: 0.4460\n",
      "Epoch 3/100\n",
      "7614/7614 - 4s - loss: 0.9348 - acc: 0.6546 - val_loss: 1.1131 - val_acc: 0.4513\n",
      "Epoch 4/100\n",
      "7614/7614 - 4s - loss: 0.8449 - acc: 0.6882 - val_loss: 1.0793 - val_acc: 0.4738\n",
      "Epoch 5/100\n",
      "7614/7614 - 4s - loss: 0.7867 - acc: 0.7024 - val_loss: 1.0423 - val_acc: 0.5059\n",
      "Epoch 6/100\n",
      "7614/7614 - 4s - loss: 0.7501 - acc: 0.7121 - val_loss: 1.0233 - val_acc: 0.5219\n",
      "Epoch 7/100\n",
      "7614/7614 - 4s - loss: 0.7201 - acc: 0.7247 - val_loss: 1.0043 - val_acc: 0.5433\n",
      "Epoch 8/100\n",
      "7614/7614 - 4s - loss: 0.6983 - acc: 0.7276 - val_loss: 0.9868 - val_acc: 0.5572\n",
      "Epoch 9/100\n",
      "7614/7614 - 4s - loss: 0.6707 - acc: 0.7410 - val_loss: 0.9448 - val_acc: 0.5786\n",
      "Epoch 10/100\n",
      "7614/7614 - 4s - loss: 0.6577 - acc: 0.7447 - val_loss: 0.9339 - val_acc: 0.6043\n",
      "Epoch 11/100\n",
      "7614/7614 - 4s - loss: 0.6369 - acc: 0.7548 - val_loss: 0.9140 - val_acc: 0.6075\n",
      "Epoch 12/100\n",
      "7614/7614 - 4s - loss: 0.6267 - acc: 0.7569 - val_loss: 0.9026 - val_acc: 0.6246\n",
      "Epoch 13/100\n",
      "7614/7614 - 4s - loss: 0.6144 - acc: 0.7618 - val_loss: 0.8771 - val_acc: 0.6374\n",
      "Epoch 14/100\n",
      "7614/7614 - 4s - loss: 0.6068 - acc: 0.7662 - val_loss: 0.8851 - val_acc: 0.6342\n",
      "Epoch 15/100\n",
      "7614/7614 - 4s - loss: 0.6001 - acc: 0.7619 - val_loss: 0.8862 - val_acc: 0.6353\n",
      "Epoch 16/100\n",
      "7614/7614 - 4s - loss: 0.5912 - acc: 0.7694 - val_loss: 0.8707 - val_acc: 0.6396\n",
      "Epoch 17/100\n",
      "7614/7614 - 4s - loss: 0.5874 - acc: 0.7671 - val_loss: 0.8665 - val_acc: 0.6492\n",
      "Epoch 18/100\n",
      "7614/7614 - 4s - loss: 0.5837 - acc: 0.7742 - val_loss: 0.8600 - val_acc: 0.6492\n",
      "Epoch 19/100\n",
      "7614/7614 - 4s - loss: 0.5742 - acc: 0.7758 - val_loss: 0.8757 - val_acc: 0.6503\n",
      "Epoch 20/100\n",
      "7614/7614 - 4s - loss: 0.5727 - acc: 0.7755 - val_loss: 0.8508 - val_acc: 0.6610\n",
      "Epoch 21/100\n",
      "7614/7614 - 4s - loss: 0.5684 - acc: 0.7740 - val_loss: 0.8534 - val_acc: 0.6535\n",
      "Epoch 22/100\n",
      "7614/7614 - 4s - loss: 0.5654 - acc: 0.7775 - val_loss: 0.8444 - val_acc: 0.6578\n",
      "Epoch 23/100\n",
      "7614/7614 - 4s - loss: 0.5577 - acc: 0.7857 - val_loss: 0.8569 - val_acc: 0.6545\n",
      "Epoch 24/100\n",
      "7614/7614 - 4s - loss: 0.5551 - acc: 0.7809 - val_loss: 0.8626 - val_acc: 0.6556\n",
      "Epoch 25/100\n",
      "7614/7614 - 4s - loss: 0.5557 - acc: 0.7799 - val_loss: 0.8748 - val_acc: 0.6481\n",
      "Epoch 26/100\n",
      "7614/7614 - 4s - loss: 0.5528 - acc: 0.7825 - val_loss: 0.8483 - val_acc: 0.6620\n",
      "Epoch 27/100\n",
      "7614/7614 - 4s - loss: 0.5481 - acc: 0.7842 - val_loss: 0.8567 - val_acc: 0.6631\n",
      "Epoch 28/100\n",
      "7614/7614 - 4s - loss: 0.5424 - acc: 0.7872 - val_loss: 0.8536 - val_acc: 0.6620\n",
      "Epoch 29/100\n",
      "7614/7614 - 4s - loss: 0.5475 - acc: 0.7843 - val_loss: 0.8483 - val_acc: 0.6642\n",
      "Epoch 30/100\n",
      "7614/7614 - 4s - loss: 0.5339 - acc: 0.7888 - val_loss: 0.8541 - val_acc: 0.6620\n",
      "Epoch 31/100\n",
      "7614/7614 - 4s - loss: 0.5375 - acc: 0.7883 - val_loss: 0.8437 - val_acc: 0.6695\n",
      "Epoch 32/100\n",
      "7614/7614 - 4s - loss: 0.5307 - acc: 0.7922 - val_loss: 0.8435 - val_acc: 0.6717\n",
      "Epoch 33/100\n",
      "7614/7614 - 4s - loss: 0.5352 - acc: 0.7891 - val_loss: 0.8414 - val_acc: 0.6738\n",
      "Epoch 34/100\n",
      "7614/7614 - 4s - loss: 0.5293 - acc: 0.7935 - val_loss: 0.8413 - val_acc: 0.6738\n",
      "Epoch 35/100\n",
      "7614/7614 - 4s - loss: 0.5265 - acc: 0.7928 - val_loss: 0.8616 - val_acc: 0.6642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "7614/7614 - 4s - loss: 0.5263 - acc: 0.7938 - val_loss: 0.8759 - val_acc: 0.6652\n",
      "Epoch 37/100\n",
      "7614/7614 - 4s - loss: 0.5241 - acc: 0.7917 - val_loss: 0.8602 - val_acc: 0.6631\n",
      "Epoch 38/100\n",
      "7614/7614 - 4s - loss: 0.5202 - acc: 0.7937 - val_loss: 0.8598 - val_acc: 0.6663\n",
      "Epoch 39/100\n",
      "7614/7614 - 4s - loss: 0.5190 - acc: 0.7967 - val_loss: 0.8543 - val_acc: 0.6695\n",
      "Epoch 40/100\n",
      "7614/7614 - 4s - loss: 0.5203 - acc: 0.7943 - val_loss: 0.8555 - val_acc: 0.6652\n",
      "Epoch 41/100\n",
      "7614/7614 - 4s - loss: 0.5188 - acc: 0.7947 - val_loss: 0.8509 - val_acc: 0.6684\n",
      "Epoch 42/100\n",
      "7614/7614 - 4s - loss: 0.5198 - acc: 0.7943 - val_loss: 0.8470 - val_acc: 0.6706\n",
      "Epoch 43/100\n",
      "7614/7614 - 4s - loss: 0.5112 - acc: 0.7933 - val_loss: 0.8504 - val_acc: 0.6663\n",
      "Epoch 44/100\n",
      "7614/7614 - 4s - loss: 0.5084 - acc: 0.8018 - val_loss: 0.8333 - val_acc: 0.6706\n",
      "Epoch 45/100\n",
      "7614/7614 - 4s - loss: 0.5077 - acc: 0.7963 - val_loss: 0.8560 - val_acc: 0.6674\n",
      "Epoch 46/100\n",
      "7614/7614 - 4s - loss: 0.4987 - acc: 0.8035 - val_loss: 0.8408 - val_acc: 0.6706\n",
      "Epoch 47/100\n",
      "7614/7614 - 4s - loss: 0.5043 - acc: 0.7983 - val_loss: 0.8502 - val_acc: 0.6695\n",
      "Epoch 48/100\n",
      "7614/7614 - 4s - loss: 0.5034 - acc: 0.7993 - val_loss: 0.8411 - val_acc: 0.6717\n",
      "Epoch 49/100\n",
      "7614/7614 - 4s - loss: 0.5029 - acc: 0.8031 - val_loss: 0.8447 - val_acc: 0.6695\n",
      "Epoch 50/100\n",
      "7614/7614 - 4s - loss: 0.5037 - acc: 0.7998 - val_loss: 0.8641 - val_acc: 0.6684\n",
      "Epoch 51/100\n",
      "7614/7614 - 4s - loss: 0.4988 - acc: 0.8072 - val_loss: 0.8617 - val_acc: 0.6663\n",
      "Epoch 52/100\n",
      "7614/7614 - 4s - loss: 0.4972 - acc: 0.8033 - val_loss: 0.8630 - val_acc: 0.6684\n",
      "Epoch 53/100\n",
      "7614/7614 - 4s - loss: 0.4952 - acc: 0.8051 - val_loss: 0.8499 - val_acc: 0.6684\n",
      "Epoch 54/100\n",
      "7614/7614 - 4s - loss: 0.4950 - acc: 0.8054 - val_loss: 0.8676 - val_acc: 0.6663\n",
      "Epoch 55/100\n",
      "7614/7614 - 4s - loss: 0.4910 - acc: 0.8055 - val_loss: 0.8613 - val_acc: 0.6674\n",
      "Epoch 56/100\n",
      "7614/7614 - 4s - loss: 0.4925 - acc: 0.8044 - val_loss: 0.8648 - val_acc: 0.6674\n",
      "Epoch 57/100\n",
      "7614/7614 - 4s - loss: 0.4950 - acc: 0.8043 - val_loss: 0.8555 - val_acc: 0.6695\n",
      "Epoch 58/100\n",
      "7614/7614 - 4s - loss: 0.4906 - acc: 0.8094 - val_loss: 0.8695 - val_acc: 0.6663\n",
      "Epoch 59/100\n",
      "7614/7614 - 4s - loss: 0.4909 - acc: 0.8058 - val_loss: 0.8705 - val_acc: 0.6663\n",
      "Epoch 60/100\n",
      "7614/7614 - 4s - loss: 0.4861 - acc: 0.8101 - val_loss: 0.8668 - val_acc: 0.6674\n",
      "Epoch 61/100\n",
      "7614/7614 - 4s - loss: 0.4915 - acc: 0.8056 - val_loss: 0.8919 - val_acc: 0.6620\n",
      "Epoch 62/100\n",
      "7614/7614 - 4s - loss: 0.4861 - acc: 0.8030 - val_loss: 0.8689 - val_acc: 0.6642\n",
      "Epoch 63/100\n",
      "7614/7614 - 4s - loss: 0.4773 - acc: 0.8125 - val_loss: 0.8620 - val_acc: 0.6652\n",
      "Epoch 64/100\n",
      "7614/7614 - 4s - loss: 0.4859 - acc: 0.8034 - val_loss: 0.8630 - val_acc: 0.6663\n",
      "Epoch 65/100\n",
      "7614/7614 - 4s - loss: 0.4824 - acc: 0.8080 - val_loss: 0.8633 - val_acc: 0.6642\n",
      "Epoch 66/100\n",
      "7614/7614 - 4s - loss: 0.4822 - acc: 0.8076 - val_loss: 0.8684 - val_acc: 0.6674\n",
      "Epoch 67/100\n",
      "7614/7614 - 4s - loss: 0.4782 - acc: 0.8086 - val_loss: 0.8694 - val_acc: 0.6684\n",
      "Epoch 68/100\n",
      "7614/7614 - 4s - loss: 0.4781 - acc: 0.8106 - val_loss: 0.8732 - val_acc: 0.6684\n",
      "Epoch 69/100\n",
      "7614/7614 - 4s - loss: 0.4741 - acc: 0.8170 - val_loss: 0.8708 - val_acc: 0.6663\n",
      "Epoch 70/100\n",
      "7614/7614 - 4s - loss: 0.4740 - acc: 0.8111 - val_loss: 0.8684 - val_acc: 0.6706\n",
      "Epoch 71/100\n",
      "7614/7614 - 4s - loss: 0.4752 - acc: 0.8144 - val_loss: 0.8709 - val_acc: 0.6727\n",
      "Epoch 72/100\n",
      "7614/7614 - 4s - loss: 0.4813 - acc: 0.8044 - val_loss: 0.8823 - val_acc: 0.6674\n",
      "Epoch 73/100\n",
      "7614/7614 - 4s - loss: 0.4694 - acc: 0.8147 - val_loss: 0.8931 - val_acc: 0.6695\n",
      "Epoch 74/100\n",
      "7614/7614 - 4s - loss: 0.4677 - acc: 0.8142 - val_loss: 0.8720 - val_acc: 0.6738\n",
      "Epoch 75/100\n",
      "7614/7614 - 4s - loss: 0.4728 - acc: 0.8101 - val_loss: 0.8836 - val_acc: 0.6706\n",
      "Epoch 76/100\n",
      "7614/7614 - 4s - loss: 0.4684 - acc: 0.8125 - val_loss: 0.8856 - val_acc: 0.6727\n",
      "Epoch 77/100\n",
      "7614/7614 - 4s - loss: 0.4696 - acc: 0.8127 - val_loss: 0.8844 - val_acc: 0.6663\n",
      "Epoch 78/100\n",
      "7614/7614 - 4s - loss: 0.4649 - acc: 0.8172 - val_loss: 0.9101 - val_acc: 0.6599\n",
      "Epoch 79/100\n",
      "7614/7614 - 4s - loss: 0.4711 - acc: 0.8191 - val_loss: 0.9107 - val_acc: 0.6610\n",
      "Epoch 80/100\n",
      "7614/7614 - 4s - loss: 0.4663 - acc: 0.8164 - val_loss: 0.8925 - val_acc: 0.6631\n",
      "Epoch 81/100\n",
      "7614/7614 - 4s - loss: 0.4679 - acc: 0.8157 - val_loss: 0.8957 - val_acc: 0.6684\n",
      "Epoch 82/100\n",
      "7614/7614 - 4s - loss: 0.4690 - acc: 0.8139 - val_loss: 0.8844 - val_acc: 0.6759\n",
      "Epoch 83/100\n",
      "7614/7614 - 4s - loss: 0.4657 - acc: 0.8139 - val_loss: 0.8920 - val_acc: 0.6706\n",
      "Epoch 84/100\n",
      "7614/7614 - 4s - loss: 0.4593 - acc: 0.8231 - val_loss: 0.8966 - val_acc: 0.6717\n",
      "Epoch 85/100\n",
      "7614/7614 - 4s - loss: 0.4647 - acc: 0.8177 - val_loss: 0.8753 - val_acc: 0.6770\n",
      "Epoch 86/100\n",
      "7614/7614 - 4s - loss: 0.4631 - acc: 0.8170 - val_loss: 0.9077 - val_acc: 0.6706\n",
      "Epoch 87/100\n",
      "7614/7614 - 4s - loss: 0.4526 - acc: 0.8274 - val_loss: 0.8887 - val_acc: 0.6759\n",
      "Epoch 88/100\n",
      "7614/7614 - 4s - loss: 0.4594 - acc: 0.8169 - val_loss: 0.8973 - val_acc: 0.6727\n",
      "Epoch 89/100\n",
      "7614/7614 - 4s - loss: 0.4608 - acc: 0.8168 - val_loss: 0.9116 - val_acc: 0.6738\n",
      "Epoch 90/100\n",
      "7614/7614 - 4s - loss: 0.4631 - acc: 0.8157 - val_loss: 0.8928 - val_acc: 0.6749\n",
      "Epoch 91/100\n",
      "7614/7614 - 4s - loss: 0.4623 - acc: 0.8147 - val_loss: 0.8891 - val_acc: 0.6727\n",
      "Epoch 92/100\n",
      "7614/7614 - 4s - loss: 0.4606 - acc: 0.8174 - val_loss: 0.9055 - val_acc: 0.6684\n",
      "Epoch 93/100\n",
      "7614/7614 - 4s - loss: 0.4580 - acc: 0.8173 - val_loss: 0.8995 - val_acc: 0.6717\n",
      "Epoch 94/100\n",
      "7614/7614 - 4s - loss: 0.4594 - acc: 0.8197 - val_loss: 0.9099 - val_acc: 0.6684\n",
      "Epoch 95/100\n",
      "7614/7614 - 4s - loss: 0.4547 - acc: 0.8180 - val_loss: 0.8907 - val_acc: 0.6781\n",
      "Epoch 96/100\n",
      "7614/7614 - 4s - loss: 0.4564 - acc: 0.8168 - val_loss: 0.9008 - val_acc: 0.6706\n",
      "Epoch 97/100\n",
      "7614/7614 - 4s - loss: 0.4530 - acc: 0.8195 - val_loss: 0.8721 - val_acc: 0.6759\n",
      "Epoch 98/100\n",
      "7614/7614 - 4s - loss: 0.4519 - acc: 0.8224 - val_loss: 0.9061 - val_acc: 0.6727\n",
      "Epoch 99/100\n",
      "7614/7614 - 4s - loss: 0.4490 - acc: 0.8230 - val_loss: 0.9039 - val_acc: 0.6727\n",
      "Epoch 100/100\n",
      "7614/7614 - 4s - loss: 0.4559 - acc: 0.8165 - val_loss: 0.8777 - val_acc: 0.6770\n",
      "Evaluate 0.67807484\n",
      "Fold # 9    Train: (7787, 5, 90)   Test: (762, 5, 90)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7787 samples, validate on 762 samples\n",
      "Epoch 1/100\n",
      "7787/7787 - 8s - loss: 1.4646 - acc: 0.3684 - val_loss: 1.3458 - val_acc: 0.3976\n",
      "Epoch 2/100\n",
      "7787/7787 - 4s - loss: 1.1536 - acc: 0.5403 - val_loss: 1.1787 - val_acc: 0.5840\n",
      "Epoch 3/100\n",
      "7787/7787 - 4s - loss: 0.9807 - acc: 0.6242 - val_loss: 1.0528 - val_acc: 0.5958\n",
      "Epoch 4/100\n",
      "7787/7787 - 4s - loss: 0.8796 - acc: 0.6845 - val_loss: 1.0004 - val_acc: 0.5984\n",
      "Epoch 5/100\n",
      "7787/7787 - 4s - loss: 0.8133 - acc: 0.7004 - val_loss: 0.9515 - val_acc: 0.6115\n",
      "Epoch 6/100\n",
      "7787/7787 - 4s - loss: 0.7654 - acc: 0.7140 - val_loss: 0.9283 - val_acc: 0.6220\n",
      "Epoch 7/100\n",
      "7787/7787 - 4s - loss: 0.7334 - acc: 0.7171 - val_loss: 0.9107 - val_acc: 0.6325\n",
      "Epoch 8/100\n",
      "7787/7787 - 4s - loss: 0.7045 - acc: 0.7284 - val_loss: 0.8798 - val_acc: 0.6430\n",
      "Epoch 9/100\n",
      "7787/7787 - 4s - loss: 0.6795 - acc: 0.7410 - val_loss: 0.8609 - val_acc: 0.6483\n",
      "Epoch 10/100\n",
      "7787/7787 - 4s - loss: 0.6607 - acc: 0.7459 - val_loss: 0.8542 - val_acc: 0.6483\n",
      "Epoch 11/100\n",
      "7787/7787 - 4s - loss: 0.6428 - acc: 0.7441 - val_loss: 0.8358 - val_acc: 0.6601\n",
      "Epoch 12/100\n",
      "7787/7787 - 4s - loss: 0.6319 - acc: 0.7561 - val_loss: 0.8375 - val_acc: 0.6627\n",
      "Epoch 13/100\n",
      "7787/7787 - 4s - loss: 0.6242 - acc: 0.7554 - val_loss: 0.8338 - val_acc: 0.6627\n",
      "Epoch 14/100\n",
      "7787/7787 - 4s - loss: 0.6094 - acc: 0.7641 - val_loss: 0.8165 - val_acc: 0.6588\n",
      "Epoch 15/100\n",
      "7787/7787 - 4s - loss: 0.6014 - acc: 0.7629 - val_loss: 0.8042 - val_acc: 0.6640\n",
      "Epoch 16/100\n",
      "7787/7787 - 4s - loss: 0.5949 - acc: 0.7676 - val_loss: 0.8161 - val_acc: 0.6522\n",
      "Epoch 17/100\n",
      "7787/7787 - 4s - loss: 0.5888 - acc: 0.7714 - val_loss: 0.8022 - val_acc: 0.6522\n",
      "Epoch 18/100\n",
      "7787/7787 - 4s - loss: 0.5802 - acc: 0.7706 - val_loss: 0.8051 - val_acc: 0.6535\n",
      "Epoch 19/100\n",
      "7787/7787 - 4s - loss: 0.5747 - acc: 0.7751 - val_loss: 0.8019 - val_acc: 0.6483\n",
      "Epoch 20/100\n",
      "7787/7787 - 4s - loss: 0.5756 - acc: 0.7736 - val_loss: 0.7819 - val_acc: 0.6601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "7787/7787 - 4s - loss: 0.5724 - acc: 0.7754 - val_loss: 0.7926 - val_acc: 0.6575\n",
      "Epoch 22/100\n",
      "7787/7787 - 4s - loss: 0.5658 - acc: 0.7744 - val_loss: 0.7802 - val_acc: 0.6601\n",
      "Epoch 23/100\n",
      "7787/7787 - 4s - loss: 0.5597 - acc: 0.7809 - val_loss: 0.7932 - val_acc: 0.6588\n",
      "Epoch 24/100\n",
      "7787/7787 - 4s - loss: 0.5530 - acc: 0.7825 - val_loss: 0.7907 - val_acc: 0.6535\n",
      "Epoch 25/100\n",
      "7787/7787 - 4s - loss: 0.5554 - acc: 0.7840 - val_loss: 0.7815 - val_acc: 0.6627\n",
      "Epoch 26/100\n",
      "7787/7787 - 4s - loss: 0.5477 - acc: 0.7831 - val_loss: 0.7936 - val_acc: 0.6614\n",
      "Epoch 27/100\n",
      "7787/7787 - 4s - loss: 0.5455 - acc: 0.7834 - val_loss: 0.7949 - val_acc: 0.6588\n",
      "Epoch 28/100\n",
      "7787/7787 - 4s - loss: 0.5392 - acc: 0.7871 - val_loss: 0.7824 - val_acc: 0.6680\n",
      "Epoch 29/100\n",
      "7787/7787 - 4s - loss: 0.5376 - acc: 0.7853 - val_loss: 0.7937 - val_acc: 0.6549\n",
      "Epoch 30/100\n",
      "7787/7787 - 4s - loss: 0.5345 - acc: 0.7884 - val_loss: 0.7891 - val_acc: 0.6627\n",
      "Epoch 31/100\n",
      "7787/7787 - 4s - loss: 0.5353 - acc: 0.7904 - val_loss: 0.7908 - val_acc: 0.6601\n",
      "Epoch 32/100\n",
      "7787/7787 - 4s - loss: 0.5387 - acc: 0.7867 - val_loss: 0.7868 - val_acc: 0.6693\n",
      "Epoch 33/100\n",
      "7787/7787 - 4s - loss: 0.5327 - acc: 0.7872 - val_loss: 0.7798 - val_acc: 0.6706\n",
      "Epoch 34/100\n",
      "7787/7787 - 4s - loss: 0.5268 - acc: 0.7945 - val_loss: 0.7843 - val_acc: 0.6601\n",
      "Epoch 35/100\n",
      "7787/7787 - 4s - loss: 0.5309 - acc: 0.7888 - val_loss: 0.7921 - val_acc: 0.6667\n",
      "Epoch 36/100\n",
      "7787/7787 - 4s - loss: 0.5280 - acc: 0.7936 - val_loss: 0.7666 - val_acc: 0.6745\n",
      "Epoch 37/100\n",
      "7787/7787 - 4s - loss: 0.5227 - acc: 0.7930 - val_loss: 0.7906 - val_acc: 0.6667\n",
      "Epoch 38/100\n",
      "7787/7787 - 4s - loss: 0.5198 - acc: 0.7949 - val_loss: 0.7863 - val_acc: 0.6654\n",
      "Epoch 39/100\n",
      "7787/7787 - 4s - loss: 0.5286 - acc: 0.7913 - val_loss: 0.7865 - val_acc: 0.6680\n",
      "Epoch 40/100\n",
      "7787/7787 - 4s - loss: 0.5211 - acc: 0.7917 - val_loss: 0.7825 - val_acc: 0.6706\n",
      "Epoch 41/100\n",
      "7787/7787 - 4s - loss: 0.5161 - acc: 0.8002 - val_loss: 0.7806 - val_acc: 0.6706\n",
      "Epoch 42/100\n",
      "7787/7787 - 4s - loss: 0.5117 - acc: 0.7990 - val_loss: 0.7867 - val_acc: 0.6667\n",
      "Epoch 43/100\n",
      "7787/7787 - 4s - loss: 0.5165 - acc: 0.7954 - val_loss: 0.7778 - val_acc: 0.6719\n",
      "Epoch 44/100\n",
      "7787/7787 - 4s - loss: 0.5141 - acc: 0.7957 - val_loss: 0.7810 - val_acc: 0.6706\n",
      "Epoch 45/100\n",
      "7787/7787 - 4s - loss: 0.5109 - acc: 0.7952 - val_loss: 0.7858 - val_acc: 0.6706\n",
      "Epoch 46/100\n",
      "7787/7787 - 4s - loss: 0.5118 - acc: 0.8002 - val_loss: 0.7720 - val_acc: 0.6732\n",
      "Epoch 47/100\n",
      "7787/7787 - 4s - loss: 0.5092 - acc: 0.7981 - val_loss: 0.7803 - val_acc: 0.6693\n",
      "Epoch 48/100\n",
      "7787/7787 - 4s - loss: 0.5071 - acc: 0.7989 - val_loss: 0.7750 - val_acc: 0.6785\n",
      "Epoch 49/100\n",
      "7787/7787 - 4s - loss: 0.5002 - acc: 0.8021 - val_loss: 0.7742 - val_acc: 0.6732\n",
      "Epoch 50/100\n",
      "7787/7787 - 4s - loss: 0.5024 - acc: 0.8015 - val_loss: 0.7832 - val_acc: 0.6772\n",
      "Epoch 51/100\n",
      "7787/7787 - 4s - loss: 0.5060 - acc: 0.8024 - val_loss: 0.7904 - val_acc: 0.6732\n",
      "Epoch 52/100\n",
      "7787/7787 - 4s - loss: 0.4980 - acc: 0.8016 - val_loss: 0.7919 - val_acc: 0.6732\n",
      "Epoch 53/100\n",
      "7787/7787 - 4s - loss: 0.4977 - acc: 0.8003 - val_loss: 0.7798 - val_acc: 0.6759\n",
      "Epoch 54/100\n",
      "7787/7787 - 4s - loss: 0.4996 - acc: 0.8010 - val_loss: 0.7652 - val_acc: 0.6837\n",
      "Epoch 55/100\n",
      "7787/7787 - 4s - loss: 0.4941 - acc: 0.8035 - val_loss: 0.7777 - val_acc: 0.6785\n",
      "Epoch 56/100\n",
      "7787/7787 - 4s - loss: 0.4998 - acc: 0.7974 - val_loss: 0.7900 - val_acc: 0.6785\n",
      "Epoch 57/100\n",
      "7787/7787 - 4s - loss: 0.4921 - acc: 0.8048 - val_loss: 0.7708 - val_acc: 0.6798\n",
      "Epoch 58/100\n",
      "7787/7787 - 4s - loss: 0.4884 - acc: 0.8076 - val_loss: 0.7912 - val_acc: 0.6759\n",
      "Epoch 59/100\n",
      "7787/7787 - 4s - loss: 0.4876 - acc: 0.8061 - val_loss: 0.7676 - val_acc: 0.6824\n",
      "Epoch 60/100\n",
      "7787/7787 - 4s - loss: 0.4909 - acc: 0.8036 - val_loss: 0.7795 - val_acc: 0.6798\n",
      "Epoch 61/100\n",
      "7787/7787 - 4s - loss: 0.4839 - acc: 0.8048 - val_loss: 0.7887 - val_acc: 0.6772\n",
      "Epoch 62/100\n",
      "7787/7787 - 4s - loss: 0.4872 - acc: 0.8060 - val_loss: 0.7656 - val_acc: 0.6903\n",
      "Epoch 63/100\n",
      "7787/7787 - 4s - loss: 0.4848 - acc: 0.8074 - val_loss: 0.7956 - val_acc: 0.6745\n",
      "Epoch 64/100\n",
      "7787/7787 - 4s - loss: 0.4858 - acc: 0.8063 - val_loss: 0.7750 - val_acc: 0.6850\n",
      "Epoch 65/100\n",
      "7787/7787 - 4s - loss: 0.4832 - acc: 0.8051 - val_loss: 0.7880 - val_acc: 0.6850\n",
      "Epoch 66/100\n",
      "7787/7787 - 4s - loss: 0.4811 - acc: 0.8088 - val_loss: 0.7756 - val_acc: 0.6798\n",
      "Epoch 67/100\n",
      "7787/7787 - 4s - loss: 0.4851 - acc: 0.8079 - val_loss: 0.7920 - val_acc: 0.6864\n",
      "Epoch 68/100\n",
      "7787/7787 - 4s - loss: 0.4804 - acc: 0.8088 - val_loss: 0.7775 - val_acc: 0.6877\n",
      "Epoch 69/100\n",
      "7787/7787 - 4s - loss: 0.4783 - acc: 0.8106 - val_loss: 0.7718 - val_acc: 0.6824\n",
      "Epoch 70/100\n",
      "7787/7787 - 4s - loss: 0.4758 - acc: 0.8132 - val_loss: 0.7713 - val_acc: 0.6890\n",
      "Epoch 71/100\n",
      "7787/7787 - 4s - loss: 0.4767 - acc: 0.8130 - val_loss: 0.7715 - val_acc: 0.6877\n",
      "Epoch 72/100\n",
      "7787/7787 - 4s - loss: 0.4815 - acc: 0.8094 - val_loss: 0.7765 - val_acc: 0.6890\n",
      "Epoch 73/100\n",
      "7787/7787 - 4s - loss: 0.4759 - acc: 0.8116 - val_loss: 0.7699 - val_acc: 0.6890\n",
      "Epoch 74/100\n",
      "7787/7787 - 4s - loss: 0.4780 - acc: 0.8101 - val_loss: 0.7766 - val_acc: 0.6916\n",
      "Epoch 75/100\n",
      "7787/7787 - 4s - loss: 0.4807 - acc: 0.8057 - val_loss: 0.7511 - val_acc: 0.6982\n",
      "Epoch 76/100\n",
      "7787/7787 - 4s - loss: 0.4768 - acc: 0.8130 - val_loss: 0.7787 - val_acc: 0.6864\n",
      "Epoch 77/100\n",
      "7787/7787 - 4s - loss: 0.4724 - acc: 0.8169 - val_loss: 0.7705 - val_acc: 0.6903\n",
      "Epoch 78/100\n",
      "7787/7787 - 4s - loss: 0.4728 - acc: 0.8124 - val_loss: 0.7649 - val_acc: 0.6929\n",
      "Epoch 79/100\n",
      "7787/7787 - 4s - loss: 0.4693 - acc: 0.8152 - val_loss: 0.7696 - val_acc: 0.6969\n",
      "Epoch 80/100\n",
      "7787/7787 - 4s - loss: 0.4702 - acc: 0.8125 - val_loss: 0.7591 - val_acc: 0.6955\n",
      "Epoch 81/100\n",
      "7787/7787 - 4s - loss: 0.4659 - acc: 0.8132 - val_loss: 0.7551 - val_acc: 0.6929\n",
      "Epoch 82/100\n",
      "7787/7787 - 4s - loss: 0.4729 - acc: 0.8116 - val_loss: 0.7608 - val_acc: 0.7021\n",
      "Epoch 83/100\n",
      "7787/7787 - 4s - loss: 0.4634 - acc: 0.8134 - val_loss: 0.7614 - val_acc: 0.6916\n",
      "Epoch 84/100\n",
      "7787/7787 - 4s - loss: 0.4712 - acc: 0.8134 - val_loss: 0.7679 - val_acc: 0.6955\n",
      "Epoch 85/100\n",
      "7787/7787 - 4s - loss: 0.4660 - acc: 0.8130 - val_loss: 0.7653 - val_acc: 0.6929\n",
      "Epoch 86/100\n",
      "7787/7787 - 4s - loss: 0.4627 - acc: 0.8149 - val_loss: 0.7637 - val_acc: 0.6982\n",
      "Epoch 87/100\n",
      "7787/7787 - 4s - loss: 0.4643 - acc: 0.8187 - val_loss: 0.7528 - val_acc: 0.7008\n",
      "Epoch 88/100\n",
      "7787/7787 - 4s - loss: 0.4654 - acc: 0.8152 - val_loss: 0.7564 - val_acc: 0.6955\n",
      "Epoch 89/100\n",
      "7787/7787 - 4s - loss: 0.4640 - acc: 0.8169 - val_loss: 0.7656 - val_acc: 0.6969\n",
      "Epoch 90/100\n",
      "7787/7787 - 4s - loss: 0.4635 - acc: 0.8171 - val_loss: 0.7555 - val_acc: 0.6995\n",
      "Epoch 91/100\n",
      "7787/7787 - 4s - loss: 0.4614 - acc: 0.8165 - val_loss: 0.7481 - val_acc: 0.7021\n",
      "Epoch 92/100\n",
      "7787/7787 - 4s - loss: 0.4633 - acc: 0.8176 - val_loss: 0.7524 - val_acc: 0.6969\n",
      "Epoch 93/100\n",
      "7787/7787 - 4s - loss: 0.4628 - acc: 0.8162 - val_loss: 0.7659 - val_acc: 0.6969\n",
      "Epoch 94/100\n",
      "7787/7787 - 4s - loss: 0.4625 - acc: 0.8157 - val_loss: 0.7435 - val_acc: 0.6995\n",
      "Epoch 95/100\n",
      "7787/7787 - 4s - loss: 0.4573 - acc: 0.8171 - val_loss: 0.7677 - val_acc: 0.6982\n",
      "Epoch 96/100\n",
      "7787/7787 - 4s - loss: 0.4576 - acc: 0.8203 - val_loss: 0.7557 - val_acc: 0.7021\n",
      "Epoch 97/100\n",
      "7787/7787 - 4s - loss: 0.4622 - acc: 0.8139 - val_loss: 0.7584 - val_acc: 0.6995\n",
      "Epoch 98/100\n",
      "7787/7787 - 4s - loss: 0.4615 - acc: 0.8142 - val_loss: 0.7497 - val_acc: 0.7008\n",
      "Epoch 99/100\n",
      "7787/7787 - 4s - loss: 0.4574 - acc: 0.8155 - val_loss: 0.7445 - val_acc: 0.7008\n",
      "Epoch 100/100\n",
      "7787/7787 - 4s - loss: 0.4579 - acc: 0.8191 - val_loss: 0.7485 - val_acc: 0.7021\n",
      "Evaluate 0.70209974\n"
     ]
    }
   ],
   "source": [
    "all_scores=[]\n",
    "for i in range(10):\n",
    "    print('Fold #', i,end='  ')\n",
    "    \n",
    "    #构建数据\n",
    "    isFirst=True\n",
    "    for p in range(10):\n",
    "        if p!=i:\n",
    "            if isFirst:\n",
    "                trainX = Out_Data[p]\n",
    "                trainY = Out_Label[p]\n",
    "                #trainY_oh = Out_Label_n[p]\n",
    "                isFirst = False\n",
    "            else:\n",
    "                trainX = np.concatenate((trainX, Out_Data[p]))\n",
    "                trainY = np.concatenate((trainY, Out_Label[p]))\n",
    "                #trainY_oh = np.concatenate((trainY_oh, Out_Label_n[p]))\n",
    "        else:\n",
    "            testX = Out_Data[p]\n",
    "            testY = Out_Label[p]\n",
    "        \n",
    "    #trainX = trainX.reshape(-1,5,26*9)\n",
    "    #testX = testX.reshape(-1,5,26*9)\n",
    "    #trainX = trainX[:,:,0,:]\n",
    "    #testX = testX[:,:,0,:]\n",
    "    print('  Train:',trainX.shape,'  Test:',testX.shape)\n",
    "    \n",
    "    model=build()\n",
    "    if i==0:\n",
    "        model.summary()\n",
    "    #model.fit(trainX,trainY,batch_size=500,epochs=5)\n",
    "    history = model.fit(\n",
    "        x = trainX,\n",
    "        y = trainY,\n",
    "        epochs = 100,\n",
    "        batch_size = 500,\n",
    "        shuffle = True,\n",
    "        validation_data = (testX, testY),\n",
    "        verbose=2,\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint('./test/Best_model_'+str(i)+'.h5', \n",
    "                                                   monitor='val_acc', \n",
    "                                                   verbose=0, \n",
    "                                                   save_best_only=True, \n",
    "                                                   save_weights_only=False, \n",
    "                                                   mode='auto', \n",
    "                                                   period=1 )])\n",
    "    model.load_weights('./test/Best_model_'+str(i)+'.h5')\n",
    "    \n",
    "    val_mse, val_acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('Evaluate',val_acc)\n",
    "    all_scores.append(val_acc)\n",
    "    \n",
    "    # Predict\n",
    "    predicts = model.predict(testX)\n",
    "    AllPred_temp = np.argmax(predicts, axis=1)\n",
    "    if i == 0:\n",
    "        AllTrue = testY\n",
    "        AllPred = AllPred_temp\n",
    "    else:\n",
    "        AllTrue = np.concatenate((AllTrue,testY))\n",
    "        AllPred = np.concatenate((AllPred,AllPred_temp))\n",
    "    \n",
    "    if i==0:\n",
    "        fit_acc=np.array(history.history['acc'])*Fold_Num[i]\n",
    "        fit_loss=np.array(history.history['loss'])*Fold_Num[i]\n",
    "        fit_val_loss=np.array(history.history['val_loss'])*Fold_Num[i]\n",
    "        fit_val_acc=np.array(history.history['val_acc'])*Fold_Num[i]\n",
    "    else:\n",
    "        fit_acc=fit_acc+np.array(history.history['acc'])*Fold_Num[i]\n",
    "        fit_loss=fit_loss+np.array(history.history['loss'])*Fold_Num[i]\n",
    "        fit_val_loss=fit_val_loss+np.array(history.history['val_loss'])*Fold_Num[i]\n",
    "        fit_val_acc=fit_val_acc+np.array(history.history['val_acc'])*Fold_Num[i]\n",
    "fit_acc      = fit_acc/len(AllPred)\n",
    "fit_loss     = fit_loss/len(AllPred)\n",
    "fit_val_loss = fit_val_loss/len(AllPred)\n",
    "fit_val_acc  = fit_val_acc/len(AllPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8549,), (8549,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllTrue=np.argmax(AllTrue,axis=1)\n",
    "AllTrue.shape,AllPred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec1256adc8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fit_acc)\n",
    "plt.plot(fit_val_acc)\n",
    "plt.show()\n",
    "plt.plot(fit_loss)\n",
    "plt.plot(fit_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintScore(true,pred,savePath=None,average='macro'):\n",
    "    if savePath == None:\n",
    "        saveFile = None\n",
    "    else:\n",
    "        saveFile=open(savePath+\"Result.txt\",'a+')\n",
    "    # Main scores\n",
    "    F1=metrics.f1_score(true,pred,average=None)\n",
    "    print(\"Main scores:\")\n",
    "    print('Acc\\tF1S\\tKappa\\tF1_W\\tF1_N1\\tF1_N2\\tF1_N3\\tF1_R',file=saveFile)\n",
    "    print('%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f'% (metrics.accuracy_score(true,pred),\n",
    "                                                             metrics.f1_score(true,pred,average=average),\n",
    "                                                             metrics.cohen_kappa_score(true,pred),\n",
    "                                                             F1[0],F1[1],F1[2],F1[3],F1[4]),\n",
    "                                                             file=saveFile)\n",
    "    # Classification report\n",
    "    print(\"\\nClassification report:\",file=saveFile)\n",
    "    print(metrics.classification_report(true,pred,target_names=['Wake','N1','N2','N3','REM']),file=saveFile)\n",
    "    # Confusion matrix\n",
    "    print('Confusion matrix:',file=saveFile)\n",
    "    print(metrics.confusion_matrix(true,pred),file=saveFile)\n",
    "    # Overall scores\n",
    "    print('\\n    Accuracy\\t',metrics.accuracy_score(true,pred),file=saveFile)\n",
    "    print(' Cohen Kappa\\t',metrics.cohen_kappa_score(true,pred),file=saveFile)\n",
    "    print('    F1-Score\\t',metrics.f1_score(true,pred,average=average),'\\tAverage =',average,file=saveFile)    \n",
    "    print('   Precision\\t',metrics.precision_score(true,pred,average=average),'\\tAverage =',average,file=saveFile)\n",
    "    print('      Recall\\t',metrics.recall_score(true,pred,average=average),'\\tAverage =',average,file=saveFile)\n",
    "    # Results of each class\n",
    "    print('\\nResults of each class:',file=saveFile)\n",
    "    print('    F1-Score\\t',metrics.f1_score(true,pred,average=None),file=saveFile)\n",
    "    print('   Precision\\t',metrics.precision_score(true,pred,average=None),file=saveFile)\n",
    "    print('      Recall\\t',metrics.recall_score(true,pred,average=None),file=saveFile)\n",
    "    if savePath != None:\n",
    "        saveFile.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main scores:\n",
      "Acc\tF1S\tKappa\tF1_W\tF1_N1\tF1_N2\tF1_N3\tF1_R\n",
      "0.7487\t0.7277\t0.6771\t0.8043\t0.4614\t0.7210\t0.8432\t0.8083\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.76      0.85      0.80      1651\n",
      "          N1       0.56      0.39      0.46      1215\n",
      "          N2       0.75      0.70      0.72      2609\n",
      "          N3       0.80      0.90      0.84      2014\n",
      "         REM       0.78      0.84      0.81      1060\n",
      "\n",
      "    accuracy                           0.75      8549\n",
      "   macro avg       0.73      0.74      0.73      8549\n",
      "weighted avg       0.74      0.75      0.74      8549\n",
      "\n",
      "Confusion matrix:\n",
      "[[1410  146   67   15   13]\n",
      " [ 270  475  304    9  157]\n",
      " [ 100  170 1817  437   85]\n",
      " [   9    1  197 1807    0]\n",
      " [  66   52   46    4  892]]\n",
      "\n",
      "    Accuracy\t 0.7487425429874839\n",
      " Cohen Kappa\t 0.6770627992300613\n",
      "    F1-Score\t 0.7276607513299884 \tAverage = macro\n",
      "   Precision\t 0.7286696961089005 \tAverage = macro\n",
      "      Recall\t 0.7360277355087256 \tAverage = macro\n",
      "\n",
      "Results of each class:\n",
      "    F1-Score\t [0.80433542 0.46138902 0.72103175 0.84321045 0.80833711]\n",
      "   Precision\t [0.76010782 0.56279621 0.74742904 0.79533451 0.77768091]\n",
      "      Recall\t [0.85402786 0.3909465  0.69643542 0.89721946 0.84150943]\n"
     ]
    }
   ],
   "source": [
    "PrintScore(AllTrue, AllPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
